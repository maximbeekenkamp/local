{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Operator Training Demo: CDON Dataset\n",
    "\n",
    "This notebook demonstrates end-to-end training of neural operator models (DeepONet, FNO, UNet) on the CDON dataset.\n",
    "\n",
    "**Features:**\n",
    "- Trains on **real CDON data** for **50 epochs**\n",
    "- Minimal custom code - reuses existing codebase\n",
    "- Includes visualizations of training progress and predictions\n",
    "- Compatible with Google Colab\n",
    "\n",
    "**Models available:**\n",
    "- `deeponet`: Branch-trunk architecture (~235K params)\n",
    "- `fno`: Fourier Neural Operator (~261K params)\n",
    "- `unet`: Encoder-decoder with skip connections (~249K params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup (uncomment if running in Colab)\n",
    "# import sys\n",
    "# if 'google.colab' in sys.modules:\n",
    "#     !git clone https://github.com/YOUR_USERNAME/CMAME.git\n",
    "#     %cd CMAME\n",
    "#     !pip install -r requirements.txt -q\n",
    "\n",
    "# Standard imports - ALL from existing codebase\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path (if not in Colab)\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.core.data_processing.cdon_dataset import CDONDataset\n",
    "from src.core.models.model_factory import create_model\n",
    "from src.core.training.simple_trainer import SimpleTrainer\n",
    "from configs.training_config import TrainingConfig\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Real CDON Data\n",
    "\n",
    "Uses the existing `CDONDataset` class - no custom data loading code needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory (adjust path if needed)\n",
    "DATA_DIR = project_root / 'data' / 'CDONData'\n",
    "\n",
    "# Create datasets using existing CDONDataset class\n",
    "train_dataset = CDONDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    split='train',\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "val_dataset = CDONDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    split='test',\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Data loaded successfully\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Val samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Inspect a sample\n",
    "sample_input, sample_target = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "print(f\"  Input: {sample_input.shape}\")\n",
    "print(f\"  Target: {sample_target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3: Choose Model Architecture\n\n**Change `MODEL_ARCH` below to try different models:**\n- `'deeponet'`: Branch-trunk architecture\n- `'fno'`: Fourier Neural Operator\n- `'unet'`: U-Net encoder-decoder\n- `'all'`: **Train all three models and compare** (NEW!)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choose model architecture (change this to experiment)\nMODEL_ARCH = 'deeponet'  # Options: 'deeponet', 'fno', 'unet', 'all'\n\n# Check if training all models\nif MODEL_ARCH == 'all':\n    models_to_train = ['deeponet', 'fno', 'unet']\n    models = {}\n    \n    print(f\"‚úì Will train all {len(models_to_train)} models\")\n    print(f\"  Models: {', '.join([m.upper() for m in models_to_train])}\")\n    \n    # Create all models\n    for arch in models_to_train:\n        models[arch] = create_model(arch)\n        num_params = sum(p.numel() for p in models[arch].parameters() if p.requires_grad)\n        print(f\"  {arch.upper()}: {num_params:,} parameters\")\nelse:\n    # Single model training\n    model = create_model(MODEL_ARCH)\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"‚úì Created {MODEL_ARCH.upper()} model\")\n    print(f\"  Parameters: {num_params:,}\")\n    print(f\"\\nModel architecture:\")\n    print(model)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Configure Training\n",
    "\n",
    "Uses existing `TrainingConfig` dataclass - all hyperparameters in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create training configuration using existing TrainingConfig\nconfig = TrainingConfig(\n    # Training\n    num_epochs=50,\n    learning_rate=1e-3,\n    batch_size=BATCH_SIZE,\n    weight_decay=1e-4,\n    \n    # Scheduler\n    scheduler_type='cosine',\n    cosine_eta_min=1e-6,\n    \n    # Evaluation\n    eval_metrics=['field_error', 'spectrum_error'],\n    eval_frequency=1,\n    \n    # Checkpointing (will be customized per model if training all)\n    checkpoint_dir=f'checkpoints/{MODEL_ARCH}_real_50epochs',\n    save_best=True,\n    save_latest=True,\n    \n    # Device (use GPU if available)\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    num_workers=2,\n    \n    # Logging\n    verbose=True\n)\n\nprint(f\"‚úì Training configuration:\")\nprint(f\"  Epochs: {config.num_epochs}\")\nprint(f\"  Learning rate: {config.learning_rate}\")\nprint(f\"  Scheduler: {config.scheduler_type}\")\nprint(f\"  Device: {config.device}\")\nif MODEL_ARCH == 'all':\n    print(f\"  Training mode: ALL MODELS\")\nelse:\n    print(f\"  Checkpoint dir: {config.checkpoint_dir}\")"
  },
  {
   "cell_type": "code",
   "source": "# Final summary before training\nprint(f\"{'='*70}\")\nprint(f\"LOSS CONFIGURATION SUMMARY\")\nprint(f\"{'='*70}\")\n\nprint(f\"\\n‚úì Loss Type: {LOSS_TYPE.upper()}\")\nprint(f\"‚úì Loss Module: {type(criterion).__name__}\")\nprint(f\"‚úì Configuration Validated: ‚úì\")\n\n# Show loss components\nfrom src.core.evaluation.loss_factory import CombinedLoss\n\nif isinstance(criterion, CombinedLoss):\n    print(f\"\\nüì¶ Combined Loss Components:\")\n    print(f\"  1. Base loss: {type(criterion.base_loss).__name__}\")\n    print(f\"  2. Spectral loss: {type(criterion.spectral_loss).__name__}\")\n    print(f\"  3. Lambda spectral: {criterion.lambda_spectral}\")\n    \n    print(f\"\\nüí° Total loss = Base loss + {criterion.lambda_spectral} √ó Spectral loss\")\nelse:\n    print(f\"\\nüì¶ Single Loss Component:\")\n    print(f\"  {type(criterion).__name__}\")\n\n# Check if weight optimizer will be needed\nrequires_weight_optimizer = LOSS_TYPE == 'sa-bsp'\n\nprint(f\"\\nüîß Trainer Configuration:\")\nprint(f\"  Model optimizer: Adam (for model parameters)\")\nif requires_weight_optimizer:\n    print(f\"  Weight optimizer: Adam (for adaptive weights) ‚Üê WILL BE CREATED\")\n    print(f\"    ‚Üí Separate optimizer for SA-BSP adaptive weights\")\nelse:\n    print(f\"  Weight optimizer: None\")\n\nprint(f\"\\nüéØ Expected Loss Behavior:\")\nif LOSS_TYPE == 'baseline':\n    print(f\"  - Loss scale: ~0.1 - 2.0 (Relative L2 normalized)\")\n    print(f\"  - Focuses on: Overall field accuracy\")\nelif LOSS_TYPE == 'bsp':\n    print(f\"  - Loss scale: May be higher (combined MSE + spectral)\")\n    print(f\"  - Focuses on: Field accuracy + frequency spectrum matching\")\n    print(f\"  - Better for: Mitigating spectral bias\")\nelif LOSS_TYPE == 'sa-bsp':\n    print(f\"  - Loss scale: May be higher (combined MSE + adaptive spectral)\")\n    print(f\"  - Focuses on: Field accuracy + adaptive frequency emphasis\")\n    print(f\"  - Better for: Automatically learning which frequencies matter\")\n    print(f\"  - Adaptive weights will evolve during training\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"‚úì Loss configuration complete - ready for trainer creation\")\nprint(f\"{'='*70}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Training logic - handles both single model and all models\nif MODEL_ARCH == 'all':\n    # Train all models sequentially\n    training_results = {}\n    trainers = {}\n    \n    for arch in models_to_train:\n        print(f\"\\n{'='*70}\")\n        print(f\"Training {arch.upper()}\")\n        print(f\"{'='*70}\\n\")\n        \n        # Create model-specific config\n        model_config = TrainingConfig(\n            num_epochs=config.num_epochs,\n            learning_rate=config.learning_rate,\n            batch_size=config.batch_size,\n            weight_decay=config.weight_decay,\n            scheduler_type=config.scheduler_type,\n            cosine_eta_min=config.cosine_eta_min,\n            eval_metrics=config.eval_metrics,\n            eval_frequency=config.eval_frequency,\n            checkpoint_dir=f'checkpoints/{arch}_real_50epochs',\n            save_best=True,\n            save_latest=True,\n            device=config.device,\n            num_workers=config.num_workers,\n            verbose=True\n        )\n        \n        # Create trainer (NOW WITH REQUIRED LOSS_CONFIG)\n        trainer = SimpleTrainer(\n            model=models[arch],\n            train_loader=train_loader,\n            val_loader=val_loader,\n            config=model_config,\n            loss_config=selected_loss_config,  # ‚Üê NEW: Required parameter\n            experiment_name=f'{arch}_real_50epochs'\n        )\n        \n        # Verify SA-BSP weight optimizer if applicable\n        if LOSS_TYPE == 'sa-bsp':\n            assert trainer.weight_optimizer is not None, \\\n                \"SA-BSP should create weight_optimizer\"\n            print(f\"  ‚úì Weight optimizer created for SA-BSP\")\n        \n        # Train\n        results = trainer.train()\n        \n        # Store results and trainer\n        training_results[arch] = results\n        trainers[arch] = trainer\n        \n        print(f\"\\n‚úì {arch.upper()} training complete!\")\n        print(f\"  Best val loss: {results['best_val_loss']:.6f}\")\n        print(f\"  Checkpoints: {trainer.checkpoint_dir}\")\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"ALL MODELS TRAINING COMPLETE!\")\n    print(f\"{'='*70}\")\n    \nelse:\n    # Single model training (WITH REQUIRED LOSS_CONFIG)\n    trainer = SimpleTrainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config,\n        loss_config=selected_loss_config,  # ‚Üê NEW: Required parameter\n        experiment_name=f'{MODEL_ARCH}_real_50epochs'\n    )\n    \n    print(f\"‚úì Trainer initialized\")\n    print(f\"  Device: {trainer.device}\")\n    print(f\"  Optimizer: {type(trainer.optimizer).__name__}\")\n    print(f\"  Scheduler: {type(trainer.scheduler).__name__}\")\n    print(f\"  Loss function: {type(trainer.criterion).__name__}\")\n    \n    # Verify SA-BSP weight optimizer if applicable\n    if LOSS_TYPE == 'sa-bsp':\n        if trainer.weight_optimizer is not None:\n            print(f\"  Weight optimizer: {type(trainer.weight_optimizer).__name__} ‚úì\")\n            print(f\"    ‚Üí Optimizing {sum(p.numel() for p in trainer.criterion.spectral_loss.adaptive_weights.parameters())} adaptive weight parameters\")\n        else:\n            print(f\"  ‚ö† WARNING: SA-BSP selected but weight_optimizer is None!\")\n    else:\n        print(f\"  Weight optimizer: None (not needed for {LOSS_TYPE})\")\n    \n    print(f\"\\nStarting training for {config.num_epochs} epochs...\\n\")\n    \n    # Train model (with rich progress bars)\n    results = trainer.train()\n    \n    print(f\"\\n‚úì Training complete!\")\n    print(f\"  Best val loss: {results['best_val_loss']:.6f}\")\n    print(f\"  Checkpoints saved to: {trainer.checkpoint_dir}\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Only run this cell for BSP or SA-BSP loss types\nif LOSS_TYPE in ['bsp', 'sa-bsp']:\n    print(f\"{'='*70}\")\n    print(f\"BSP/SA-BSP Loss Inspection\")\n    print(f\"{'='*70}\")\n    \n    # Access the spectral loss component\n    from src.core.evaluation.loss_factory import CombinedLoss\n    \n    if isinstance(criterion, CombinedLoss):\n        spectral_loss = criterion.spectral_loss\n        \n        print(f\"\\nüìä Frequency Binning Configuration:\")\n        print(f\"  Number of bins: {spectral_loss.n_bins}\")\n        print(f\"  Binning mode: {spectral_loss.binning_mode}\")\n        print(f\"  Lambda (spectral weight): {spectral_loss.lambda_bsp}\")\n        \n        # Show bin edges (example for 4000 timesteps)\n        timesteps = 4000\n        n_freq = timesteps // 2 + 1  # rfft output size\n        \n        print(f\"\\nüìè Frequency Domain:\")\n        print(f\"  Time domain length: {timesteps}\")\n        print(f\"  Frequency domain length: {n_freq}\")\n        print(f\"  Nyquist frequency index: {n_freq - 1}\")\n        \n        # Calculate bin boundaries\n        bin_size = n_freq / spectral_loss.n_bins\n        print(f\"\\nüóÇÔ∏è  Bin Structure:\")\n        print(f\"  Bin size (avg): {bin_size:.2f} frequency components per bin\")\n        \n        # Show first few bins\n        for i in range(min(5, spectral_loss.n_bins)):\n            start_idx = int(i * bin_size)\n            end_idx = int((i + 1) * bin_size)\n            print(f\"  Bin {i}: freq indices [{start_idx}, {end_idx})\")\n        \n        if spectral_loss.n_bins > 5:\n            print(f\"  ... ({spectral_loss.n_bins - 5} more bins)\")\n        \n        # SA-BSP specific: show adaptive weights\n        if LOSS_TYPE == 'sa-bsp':\n            print(f\"\\nüéØ Adaptive Weights (SA-BSP):\")\n            \n            from src.core.evaluation.adaptive_spectral_loss import SelfAdaptiveBSPLoss\n            \n            if isinstance(spectral_loss, SelfAdaptiveBSPLoss):\n                initial_weights = spectral_loss.adaptive_weights()\n                \n                print(f\"  Weight mode: {spectral_loss.adaptive_weights.mode}\")\n                print(f\"  Number of weight parameters: {initial_weights.numel()}\")\n                print(f\"\\n  Initial weights (first 10):\")\n                for i in range(min(10, len(initial_weights))):\n                    print(f\"    Bin {i}: {initial_weights[i].item():.4f}\")\n                \n                if len(initial_weights) > 10:\n                    print(f\"    ... ({len(initial_weights) - 10} more)\")\n                \n                print(f\"\\n  Weight statistics:\")\n                print(f\"    Mean: {initial_weights.mean().item():.4f}\")\n                print(f\"    Std:  {initial_weights.std().item():.4f}\")\n                print(f\"    Min:  {initial_weights.min().item():.4f}\")\n                print(f\"    Max:  {initial_weights.max().item():.4f}\")\n                \n                # Plot initial weights\n                import matplotlib.pyplot as plt\n                \n                fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n                weights_np = initial_weights.detach().cpu().numpy()\n                ax.bar(range(len(weights_np)), weights_np, alpha=0.7, color='steelblue')\n                ax.set_xlabel('Bin Index')\n                ax.set_ylabel('Weight Value')\n                ax.set_title('Initial Adaptive Weights (Before Training)')\n                ax.grid(True, alpha=0.3)\n                plt.tight_layout()\n                plt.show()\n                \n                print(f\"\\nüí° These weights will be learned during training!\")\n        \n        else:\n            print(f\"\\nüí° BSP uses fixed equal weights for all bins\")\n    \n    print(f\"\\n{'='*70}\")\n    \nelse:\n    print(f\"‚è≠Ô∏è  Skipping BSP/SA-BSP inspection (using {LOSS_TYPE} loss)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 4E: BSP/SA-BSP Specific Inspection (Conditional)\n\n**Only runs if LOSS_TYPE is 'bsp' or 'sa-bsp'**\n\nInspects frequency binning configuration and adaptive weights.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get one batch from the training data\nprint(\"Testing loss on real CDON data...\")\nprint(f\"{'='*70}\")\n\nsample_batch_input, sample_batch_target = next(iter(train_loader))\n\nprint(f\"Batch shapes:\")\nprint(f\"  Input: {sample_batch_input.shape}\")\nprint(f\"  Target: {sample_batch_target.shape}\")\n\n# Compute loss on real data (CPU is fine for testing)\ntry:\n    real_data_loss = criterion(sample_batch_input, sample_batch_target)\n    \n    print(f\"\\n‚úì Loss computed on real data successfully\")\n    print(f\"  Loss value: {real_data_loss.item():.6f}\")\n    print(f\"  Loss is finite: {torch.isfinite(real_data_loss).item()}\")\n    \n    # Test gradients\n    real_data_loss.backward()\n    print(f\"‚úì Gradients computed successfully\")\n    \n    # Check gradient magnitudes (should not be zero or extreme)\n    grad_magnitude = sample_batch_input.grad.abs().mean().item() if sample_batch_input.grad is not None else 0.0\n    print(f\"  Gradient magnitude (mean abs): {grad_magnitude:.6e}\")\n    \n    if grad_magnitude > 0:\n        print(f\"  Gradients are non-zero (good for training)\")\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå ERROR during loss computation on real data:\")\n    print(f\"  {type(e).__name__}: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise\n\nprint(f\"{'='*70}\")\nprint(f\"‚úì Loss function validated on real CDON data\")\nprint(f\"  Ready to proceed with training\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 4D: Test Loss on Sample Real Data\n\nTest the loss function on actual CDON data to catch shape mismatches or NaN issues early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create loss function using the factory\ncriterion = create_loss(selected_loss_config)\n\nprint(f\"‚úì Loss function created successfully\")\nprint(f\"\\nLoss function type: {type(criterion).__name__}\")\nprint(f\"\\nLoss module structure:\")\nprint(criterion)\n\n# Validate with dummy tensors\nprint(f\"\\n{'='*70}\")\nprint(\"Validation Test: Computing loss on dummy data\")\nprint('='*70)\n\n# Create dummy tensors [batch=4, channels=1, timesteps=1000]\ndummy_pred = torch.randn(4, 1, 1000)\ndummy_target = torch.randn(4, 1, 1000)\n\ntry:\n    # Compute loss\n    test_loss = criterion(dummy_pred, dummy_target)\n    \n    # Check if loss is finite\n    if torch.isfinite(test_loss):\n        print(f\"‚úì Loss computation successful\")\n        print(f\"  Dummy loss value: {test_loss.item():.6f}\")\n        print(f\"  Loss is finite: True\")\n        \n        # Test backward pass\n        test_loss.backward()\n        print(f\"‚úì Gradient computation successful\")\n        print(f\"  Dummy gradients computed without errors\")\n    else:\n        print(f\"‚ö† WARNING: Loss is not finite (NaN or Inf)\")\n        print(f\"  Loss value: {test_loss.item()}\")\n        \nexcept Exception as e:\n    print(f\"‚ùå ERROR during loss computation:\")\n    print(f\"  {type(e).__name__}: {e}\")\n    raise\n\nprint(f\"\\n{'='*70}\")\nprint(\"‚úì Loss function validation complete - ready for training\")\nprint('='*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 4C: Create and Validate Loss Function\n\nTest that the loss function is created correctly and computes without errors.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Choose loss type (CHANGE THIS TO EXPERIMENT)\nLOSS_TYPE = 'baseline'  # Options: 'baseline', 'bsp', 'sa-bsp'\n\n# Map loss type to configuration\nloss_config_map = {\n    'baseline': BASELINE_CONFIG,\n    'bsp': BSP_CONFIG,\n    'sa-bsp': SA_BSP_CONFIG\n}\n\n# Validate selection\nif LOSS_TYPE not in loss_config_map:\n    raise ValueError(f\"Invalid LOSS_TYPE: '{LOSS_TYPE}'. Must be one of {list(loss_config_map.keys())}\")\n\n# Get selected configuration\nselected_loss_config = loss_config_map[LOSS_TYPE]\n\nprint(f\"‚úì Selected loss type: {LOSS_TYPE.upper()}\")\nprint(f\"\\nConfiguration:\")\nprint(f\"  Description: {selected_loss_config.description}\")\nprint(f\"  Loss type: {selected_loss_config.loss_type}\")\nprint(f\"  Parameters:\")\nfor key, value in selected_loss_config.loss_params.items():\n    print(f\"    {key}: {value}\")\n\n# Additional info based on loss type\nif LOSS_TYPE == 'bsp':\n    print(f\"\\nüí° BSP Loss will combine:\")\n    print(f\"   - Base loss (MSE in real space)\")\n    print(f\"   - Spectral loss (MSPE on frequency bins)\")\n    print(f\"   - Weighted by lambda_spectral = {selected_loss_config.loss_params.get('lambda_spectral', 'N/A')}\")\nelif LOSS_TYPE == 'sa-bsp':\n    print(f\"\\nüí° SA-BSP Loss features:\")\n    print(f\"   - Adaptive per-bin weights (trainable)\")\n    print(f\"   - Separate weight optimizer will be created\")\n    print(f\"   - Weights adapt during training to emphasize difficult frequencies\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Only run for SA-BSP loss\nif LOSS_TYPE == 'sa-bsp':\n    print(f\"{'='*70}\")\n    print(\"SA-BSP Adaptive Weight Evolution Analysis\")\n    print(f\"{'='*70}\")\n    \n    from src.core.evaluation.adaptive_spectral_loss import SelfAdaptiveBSPLoss\n    \n    # Get the trained spectral loss module\n    if MODEL_ARCH == 'all':\n        # Use first model's trainer as example\n        example_trainer = trainers[models_to_train[0]]\n        example_arch = models_to_train[0]\n    else:\n        example_trainer = trainer\n        example_arch = MODEL_ARCH\n    \n    spectral_loss = example_trainer.criterion.spectral_loss\n    \n    if isinstance(spectral_loss, SelfAdaptiveBSPLoss):\n        # Get final adaptive weights\n        final_weights = spectral_loss.adaptive_weights()\n        final_weights_np = final_weights.detach().cpu().numpy()\n        \n        print(f\"\\nüìä Adaptive Weights After Training:\")\n        print(f\"  Model: {example_arch.upper()}\")\n        print(f\"  Number of bins: {len(final_weights_np)}\")\n        \n        print(f\"\\n  Final weight statistics:\")\n        print(f\"    Mean: {final_weights_np.mean():.4f}\")\n        print(f\"    Std:  {final_weights_np.std():.4f}\")\n        print(f\"    Min:  {final_weights_np.min():.4f}\")\n        print(f\"    Max:  {final_weights_np.max():.4f}\")\n        print(f\"    Range: {final_weights_np.max() - final_weights_np.min():.4f}\")\n        \n        # Find emphasized bins\n        mean_weight = final_weights_np.mean()\n        std_weight = final_weights_np.std()\n        emphasized_bins = np.where(final_weights_np > mean_weight + std_weight)[0]\n        deemphasized_bins = np.where(final_weights_np < mean_weight - std_weight)[0]\n        \n        print(f\"\\n  Frequency emphasis:\")\n        print(f\"    High-weight bins (>Œº+œÉ): {len(emphasized_bins)} bins ‚Üí {list(emphasized_bins)[:10]}\")\n        print(f\"    Low-weight bins (<Œº-œÉ):  {len(deemphasized_bins)} bins ‚Üí {list(deemphasized_bins)[:10]}\")\n        \n        # Visualize weight evolution\n        fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n        \n        # Plot 1: Final weights bar chart\n        ax = axes[0]\n        ax.bar(range(len(final_weights_np)), final_weights_np, alpha=0.7, color='steelblue')\n        ax.axhline(y=mean_weight, color='red', linestyle='--', label=f'Mean ({mean_weight:.2f})', linewidth=2)\n        ax.axhline(y=mean_weight + std_weight, color='orange', linestyle=':', label=f'Mean+Std', linewidth=1.5)\n        ax.axhline(y=mean_weight - std_weight, color='orange', linestyle=':', label=f'Mean-Std', linewidth=1.5)\n        ax.set_xlabel('Bin Index (Low‚ÜíHigh Frequency)', fontsize=12)\n        ax.set_ylabel('Weight Value', fontsize=12)\n        ax.set_title('Final Adaptive Weights After Training', fontsize=14, fontweight='bold')\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n        \n        # Plot 2: Weight distribution histogram\n        ax = axes[1]\n        ax.hist(final_weights_np, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n        ax.axvline(x=mean_weight, color='red', linestyle='--', label=f'Mean', linewidth=2)\n        ax.set_xlabel('Weight Value', fontsize=12)\n        ax.set_ylabel('Frequency (# of bins)', fontsize=12)\n        ax.set_title('Weight Value Distribution', fontsize=14, fontweight='bold')\n        ax.legend()\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        plt.suptitle(f'SA-BSP Adaptive Weight Analysis ({example_arch.upper()})', \n                     fontsize=16, fontweight='bold')\n        plt.tight_layout()\n        plt.show()\n        \n        # Interpretation\n        print(f\"\\nüí° Interpretation:\")\n        \n        weight_range = final_weights_np.max() - final_weights_np.min()\n        if weight_range < 0.5:\n            print(f\"  ‚ö° Low weight variation (range={weight_range:.2f})\")\n            print(f\"     ‚Üí Model found relatively uniform importance across frequencies\")\n        elif weight_range < 1.5:\n            print(f\"  ‚ö° Moderate weight variation (range={weight_range:.2f})\")\n            print(f\"     ‚Üí Model identified some frequency-specific challenges\")\n        else:\n            print(f\"  ‚ö° High weight variation (range={weight_range:.2f})\")\n            print(f\"     ‚Üí Model strongly emphasized certain frequency ranges\")\n        \n        # Check if high frequencies are emphasized\n        n_bins = len(final_weights_np)\n        low_freq_mean = final_weights_np[:n_bins//3].mean()\n        mid_freq_mean = final_weights_np[n_bins//3:2*n_bins//3].mean()\n        high_freq_mean = final_weights_np[2*n_bins//3:].mean()\n        \n        print(f\"\\n  Frequency range emphasis:\")\n        print(f\"    Low frequencies  (bins 0-{n_bins//3}):     avg weight = {low_freq_mean:.4f}\")\n        print(f\"    Mid frequencies  (bins {n_bins//3}-{2*n_bins//3}):   avg weight = {mid_freq_mean:.4f}\")\n        print(f\"    High frequencies (bins {2*n_bins//3}-{n_bins}): avg weight = {high_freq_mean:.4f}\")\n        \n        if high_freq_mean > low_freq_mean * 1.2:\n            print(f\"     ‚Üí Model emphasized HIGH frequencies (spectral bias detected)\")\n        elif low_freq_mean > high_freq_mean * 1.2:\n            print(f\"     ‚Üí Model emphasized LOW frequencies\")\n        else:\n            print(f\"     ‚Üí Relatively balanced frequency emphasis\")\n    \n    print(f\"\\n{'='*70}\")\n    \nelse:\n    print(f\"‚è≠Ô∏è  Skipping SA-BSP weight evolution (using {LOSS_TYPE} loss)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 10: SA-BSP Adaptive Weight Evolution (Conditional)\n\n**Only runs if LOSS_TYPE is 'sa-bsp'**\n\nVisualizes how adaptive weights changed during training.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 4B: Select Loss Type\n\n**Change `LOSS_TYPE` below to experiment with different loss functions:**\n- `'baseline'`: Standard Relative L2 loss (default)\n- `'bsp'`: BSP loss - better for spectral bias mitigation\n- `'sa-bsp'`: Self-Adaptive BSP - learns frequency weights during training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import loss configurations from existing codebase\nfrom configs.loss_config import BASELINE_CONFIG, BSP_CONFIG, SA_BSP_CONFIG\nfrom src.core.evaluation.loss_factory import create_loss\n\nprint(\"‚úì Loss configurations imported successfully\")\nprint(\"\\nAvailable loss types:\")\nprint(f\"  1. BASELINE: {BASELINE_CONFIG.description}\")\nprint(f\"  2. BSP:      {BSP_CONFIG.description}\")\nprint(f\"  3. SA-BSP:   {SA_BSP_CONFIG.description}\")\n\n# Show configuration details\nprint(\"\\n\" + \"=\"*70)\nprint(\"Configuration Details:\")\nprint(\"=\"*70)\n\nfor name, config in [('BASELINE', BASELINE_CONFIG), ('BSP', BSP_CONFIG), ('SA-BSP', SA_BSP_CONFIG)]:\n    print(f\"\\n{name}:\")\n    print(f\"  Loss type: {config.loss_type}\")\n    print(f\"  Parameters: {config.loss_params}\")\n    \nprint(\"\\n\" + \"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 4A: Import Loss Configurations\n\n**NEW: Configurable Loss Functions**\n\nImport loss configurations to enable:\n- **Baseline**: Standard Relative L2 loss\n- **BSP**: Binned Spectral Power loss (mitigates spectral bias)\n- **SA-BSP**: Self-Adaptive BSP with learnable weights",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Trainer and Train\n",
    "\n",
    "Uses existing `SimpleTrainer` class - handles all training logic with rich progress bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training logic - handles both single model and all models\nif MODEL_ARCH == 'all':\n    # Train all models sequentially\n    training_results = {}\n    trainers = {}\n    \n    for arch in models_to_train:\n        print(f\"\\n{'='*70}\")\n        print(f\"Training {arch.upper()}\")\n        print(f\"{'='*70}\\n\")\n        \n        # Create model-specific config\n        model_config = TrainingConfig(\n            num_epochs=config.num_epochs,\n            learning_rate=config.learning_rate,\n            batch_size=config.batch_size,\n            weight_decay=config.weight_decay,\n            scheduler_type=config.scheduler_type,\n            cosine_eta_min=config.cosine_eta_min,\n            eval_metrics=config.eval_metrics,\n            eval_frequency=config.eval_frequency,\n            checkpoint_dir=f'checkpoints/{arch}_real_50epochs',\n            save_best=True,\n            save_latest=True,\n            device=config.device,\n            num_workers=config.num_workers,\n            verbose=True\n        )\n        \n        # Create trainer\n        trainer = SimpleTrainer(\n            model=models[arch],\n            train_loader=train_loader,\n            val_loader=val_loader,\n            config=model_config,\n            experiment_name=f'{arch}_real_50epochs'\n        )\n        \n        # Train\n        results = trainer.train()\n        \n        # Store results and trainer\n        training_results[arch] = results\n        trainers[arch] = trainer\n        \n        print(f\"\\n‚úì {arch.upper()} training complete!\")\n        print(f\"  Best val loss: {results['best_val_loss']:.6f}\")\n        print(f\"  Checkpoints: {trainer.checkpoint_dir}\")\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"ALL MODELS TRAINING COMPLETE!\")\n    print(f\"{'='*70}\")\n    \nelse:\n    # Single model training (original code)\n    trainer = SimpleTrainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config,\n        experiment_name=f'{MODEL_ARCH}_real_50epochs'\n    )\n    \n    print(f\"‚úì Trainer initialized\")\n    print(f\"  Device: {trainer.device}\")\n    print(f\"  Optimizer: {type(trainer.optimizer).__name__}\")\n    print(f\"  Scheduler: {type(trainer.scheduler).__name__}\")\n    print(f\"\\nStarting training for {config.num_epochs} epochs...\\n\")\n    \n    # Train model (with rich progress bars)\n    results = trainer.train()\n    \n    print(f\"\\n‚úì Training complete!\")\n    print(f\"  Best val loss: {results['best_val_loss']:.6f}\")\n    print(f\"  Checkpoints saved to: {trainer.checkpoint_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot training history - handles both single model and comparison\nif MODEL_ARCH == 'all':\n    # OVERLAY COMPARISON PLOT for all models\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # Color scheme\n    colors = {'deeponet': '#1f77b4', 'fno': '#ff7f0e', 'unet': '#2ca02c'}\n    \n    for arch in models_to_train:\n        results_arch = training_results[arch]\n        train_losses = [h['loss'] for h in results_arch['train_history']]\n        val_losses = [h['loss'] for h in results_arch['val_history']]\n        val_field_errors = [h['field_error'] for h in results_arch['val_history']]\n        val_spectrum_errors = [h['spectrum_error'] for h in results_arch['val_history']]\n        epochs = range(1, len(train_losses) + 1)\n        \n        color = colors[arch]\n        label = arch.upper()\n        \n        # Plot 1: Validation Loss\n        axes[0].plot(epochs, val_losses, label=label, color=color, linewidth=2, alpha=0.9)\n        \n        # Plot 2: Field Error\n        axes[1].plot(epochs, val_field_errors, label=label, color=color, linewidth=2, alpha=0.9)\n        \n        # Plot 3: Spectrum Error\n        axes[2].plot(epochs, val_spectrum_errors, label=label, color=color, linewidth=2, alpha=0.9)\n    \n    # Configure Plot 1\n    axes[0].set_xlabel('Epoch', fontsize=12)\n    axes[0].set_ylabel('Validation Loss', fontsize=12)\n    axes[0].set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n    axes[0].legend(fontsize=10)\n    axes[0].grid(True, alpha=0.3)\n    \n    # Configure Plot 2\n    axes[1].set_xlabel('Epoch', fontsize=12)\n    axes[1].set_ylabel('Field Error', fontsize=12)\n    axes[1].set_title('Field Error Comparison', fontsize=14, fontweight='bold')\n    axes[1].legend(fontsize=10)\n    axes[1].grid(True, alpha=0.3)\n    \n    # Configure Plot 3\n    axes[2].set_xlabel('Epoch', fontsize=12)\n    axes[2].set_ylabel('Spectrum Error', fontsize=12)\n    axes[2].set_title('Spectrum Error Comparison', fontsize=14, fontweight='bold')\n    axes[2].legend(fontsize=10)\n    axes[2].grid(True, alpha=0.3)\n    \n    plt.suptitle('Multi-Model Training Comparison on Real CDON Data', \n                 fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    # Print summary table\n    print(\"\\nFinal Metrics Summary:\")\n    print(f\"{'Model':<12} {'Val Loss':<12} {'Field Error':<15} {'Spectrum Error':<15}\")\n    print(\"-\" * 60)\n    for arch in models_to_train:\n        results_arch = training_results[arch]\n        final_val = results_arch['val_history'][-1]\n        print(f\"{arch.upper():<12} {final_val['loss']:<12.6f} {final_val['field_error']:<15.6f} {final_val['spectrum_error']:<15.6f}\")\n    \nelse:\n    # SINGLE MODEL PLOT (original code)\n    # Extract metrics from results\n    train_losses = [h['loss'] for h in results['train_history']]\n    val_losses = [h['loss'] for h in results['val_history']]\n    train_field_errors = [h['field_error'] for h in results['train_history']]\n    val_field_errors = [h['field_error'] for h in results['val_history']]\n    val_spectrum_errors = [h['spectrum_error'] for h in results['val_history']]\n    epochs = range(1, len(train_losses) + 1)\n    \n    # Create figure with subplots\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # Plot 1: Loss\n    axes[0].plot(epochs, train_losses, label='Train Loss', marker='o', markersize=3)\n    axes[0].plot(epochs, val_losses, label='Val Loss', marker='s', markersize=3)\n    axes[0].set_xlabel('Epoch')\n    axes[0].set_ylabel('Relative L2 Loss')\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    \n    # Plot 2: Field Error\n    axes[1].plot(epochs, train_field_errors, label='Train Field Error', marker='o', markersize=3)\n    axes[1].plot(epochs, val_field_errors, label='Val Field Error', marker='s', markersize=3)\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('Field Error')\n    axes[1].set_title('Field Error (Real Space)')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    # Plot 3: Spectrum Error\n    axes[2].plot(epochs, val_spectrum_errors, label='Val Spectrum Error', marker='s', markersize=3, color='green')\n    axes[2].set_xlabel('Epoch')\n    axes[2].set_ylabel('Spectrum Error')\n    axes[2].set_title('Spectrum Error (Frequency Space)')\n    axes[2].legend()\n    axes[2].grid(True, alpha=0.3)\n    \n    plt.suptitle(f'{MODEL_ARCH.upper()} Training on Real CDON Data ({config.num_epochs} Epochs)', \n                 fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    # Print final metrics\n    print(f\"\\nFinal Metrics:\")\n    print(f\"  Train Loss: {train_losses[-1]:.6f}\")\n    print(f\"  Val Loss: {val_losses[-1]:.6f}\")\n    print(f\"  Val Field Error: {val_field_errors[-1]:.6f}\")\n    print(f\"  Val Spectrum Error: {val_spectrum_errors[-1]:.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Evaluate Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_checkpoint_path = trainer.checkpoint_dir / 'best_model.pt'\n",
    "\n",
    "if best_checkpoint_path.exists():\n",
    "    epoch = trainer.load_checkpoint(str(best_checkpoint_path))\n",
    "    print(f\"‚úì Loaded best model from epoch {epoch}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    test_metrics = trainer.validate()\n",
    "    \n",
    "    print(f\"\\nBest Model Test Results:\")\n",
    "    print(f\"  Loss: {test_metrics['loss']:.6f}\")\n",
    "    print(f\"  Field Error: {test_metrics['field_error']:.6f}\")\n",
    "    print(f\"  Spectrum Error: {test_metrics['spectrum_error']:.6f}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Using current model state.\")\n",
    "    test_metrics = trainer.validate()\n",
    "    print(f\"\\nCurrent Model Test Results:\")\n",
    "    print(f\"  Loss: {test_metrics['loss']:.6f}\")\n",
    "    print(f\"  Field Error: {test_metrics['field_error']:.6f}\")\n",
    "    print(f\"  Spectrum Error: {test_metrics['spectrum_error']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from validation set\n",
    "model.eval()\n",
    "sample_inputs, sample_targets = next(iter(val_loader))\n",
    "sample_inputs = sample_inputs.to(config.device)\n",
    "sample_targets = sample_targets.to(config.device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    sample_preds = model(sample_inputs)\n",
    "\n",
    "# Move to CPU for plotting\n",
    "sample_inputs = sample_inputs.cpu().numpy()\n",
    "sample_targets = sample_targets.cpu().numpy()\n",
    "sample_preds = sample_preds.cpu().numpy()\n",
    "\n",
    "# Plot 3 samples\n",
    "num_samples = min(3, len(sample_inputs))\n",
    "fig, axes = plt.subplots(num_samples, 1, figsize=(14, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Extract data\n",
    "    target = sample_targets[idx, 0, :]\n",
    "    pred = sample_preds[idx, 0, :]\n",
    "    \n",
    "    # Compute error\n",
    "    error = np.abs(target - pred)\n",
    "    relative_error = np.linalg.norm(target - pred) / np.linalg.norm(target)\n",
    "    \n",
    "    # Plot\n",
    "    timesteps = np.arange(len(target))\n",
    "    ax.plot(timesteps, target, label='Ground Truth', alpha=0.8, linewidth=1.5)\n",
    "    ax.plot(timesteps, pred, label='Prediction', alpha=0.8, linewidth=1.5, linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_ylabel('Displacement')\n",
    "    ax.set_title(f'Sample {idx + 1}: Prediction vs Ground Truth (Relative Error: {relative_error:.4f})')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'{MODEL_ARCH.upper()} Sample Predictions', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nPrediction Statistics (first 3 samples):\")\n",
    "for idx in range(num_samples):\n",
    "    target = sample_targets[idx, 0, :]\n",
    "    pred = sample_preds[idx, 0, :]\n",
    "    rel_error = np.linalg.norm(target - pred) / np.linalg.norm(target)\n",
    "    print(f\"  Sample {idx + 1}: Relative Error = {rel_error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Import spectral analysis functions\nfrom src.core.visualization.spectral_analysis import (\n    plot_spectral_bias_comparison,\n    compute_spectral_bias_metric,\n    plot_spectral_bias_metrics\n)\n\n# Get predictions for spectral analysis\nif MODEL_ARCH == 'all':\n    # Use trained models to generate predictions\n    predictions_for_spectral = {}\n    \n    # Get a validation batch\n    sample_batch_input, sample_batch_target = next(iter(val_loader))\n    sample_batch_input = sample_batch_input.to(config.device)\n    \n    # Generate predictions from all models\n    for arch in models_to_train:\n        models[arch].eval()\n        with torch.no_grad():\n            pred = models[arch](sample_batch_input)\n            predictions_for_spectral[arch] = pred.cpu()\n    \n    ground_truth_spectral = sample_batch_target\n    \n    # Plot spectral bias comparison\n    print(\"\\nGenerating spectral bias comparison plot...\")\n    plot_spectral_bias_comparison(\n        predictions=predictions_for_spectral,\n        ground_truth=ground_truth_spectral,\n        title='Frequency Spectrum: Model Predictions vs Ground Truth',\n        n_bins=32,\n        show_uncertainty=True\n    )\n    \n    # Compute quantitative metrics\n    print(\"\\nSpectral Bias Metrics:\")\n    metrics_spectral = {}\n    for arch in models_to_train:\n        metrics = compute_spectral_bias_metric(\n            prediction=predictions_for_spectral[arch],\n            ground_truth=ground_truth_spectral,\n            n_bins=32\n        )\n        metrics_spectral[arch] = metrics\n        \n        print(f\"\\n{arch.upper()}:\")\n        print(f\"  Low freq error:  {metrics['low_freq_error']:.4f}\")\n        print(f\"  Mid freq error:  {metrics['mid_freq_error']:.4f}\")\n        print(f\"  High freq error: {metrics['high_freq_error']:.4f}\")\n        print(f\"  Spectral bias ratio: {metrics['spectral_bias_ratio']:.4f}\")\n    \n    # Plot metrics comparison\n    plot_spectral_bias_metrics(metrics_spectral)\n    \nelse:\n    # Single model spectral analysis\n    model.eval()\n    \n    # Get a validation batch\n    sample_batch_input, sample_batch_target = next(iter(val_loader))\n    sample_batch_input = sample_batch_input.to(config.device)\n    \n    # Generate prediction\n    with torch.no_grad():\n        pred = model(sample_batch_input)\n    \n    # Create predictions dict\n    predictions_for_spectral = {MODEL_ARCH: pred.cpu()}\n    ground_truth_spectral = sample_batch_target\n    \n    # Plot spectral comparison\n    print(\"\\nGenerating frequency spectrum plot...\")\n    plot_spectral_bias_comparison(\n        predictions=predictions_for_spectral,\n        ground_truth=ground_truth_spectral,\n        title=f'{MODEL_ARCH.upper()} Frequency Spectrum Analysis',\n        n_bins=32,\n        show_uncertainty=True\n    )\n    \n    # Compute metrics\n    metrics = compute_spectral_bias_metric(\n        prediction=pred.cpu(),\n        ground_truth=ground_truth_spectral,\n        n_bins=32\n    )\n    \n    print(f\"\\nSpectral Bias Metrics for {MODEL_ARCH.upper()}:\")\n    print(f\"  Low freq error:  {metrics['low_freq_error']:.4f}\")\n    print(f\"  Mid freq error:  {metrics['mid_freq_error']:.4f}\")\n    print(f\"  High freq error: {metrics['high_freq_error']:.4f}\")\n    print(f\"  Spectral bias ratio: {metrics['spectral_bias_ratio']:.4f}\")\n    print(f\"\\nInterpretation:\")\n    if metrics['spectral_bias_ratio'] > 2.0:\n        print(f\"  ‚ö† Significant spectral bias (ratio > 2.0)\")\n        print(f\"  Model struggles with high frequencies\")\n    elif metrics['spectral_bias_ratio'] > 1.5:\n        print(f\"  ‚ö° Moderate spectral bias (ratio > 1.5)\")\n    else:\n        print(f\"  ‚úì Low spectral bias (ratio ‚â§ 1.5)\")\n        print(f\"  Model captures frequencies well\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 9: Spectral Bias Analysis (NEW!)\n\nAnalyzes frequency spectrum of model predictions to identify spectral bias.\nShows which models capture high-frequency content better.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ‚úì Loading real CDON data using existing `CDONDataset`\n",
    "2. ‚úì Creating models using existing `create_model` factory\n",
    "3. ‚úì Training with existing `SimpleTrainer` class (50 epochs)\n",
    "4. ‚úì Visualizing training progress and predictions\n",
    "\n",
    "**Next steps:**\n",
    "- Try different model architectures by changing `MODEL_ARCH`\n",
    "- Experiment with hyperparameters in `TrainingConfig`\n",
    "- Train for more epochs for better convergence\n",
    "- Compare results across different models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}