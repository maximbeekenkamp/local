{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Neural Operator Training Demo: CDON Dataset\n\nThis notebook demonstrates end-to-end training of neural operator models (DeepONet, FNO, UNet) on the CDON dataset.\n\n**Features:**\n- Trains on **real CDON data**\n- **Sequential training with all 5 loss functions**:\n  - **BASELINE**: Relative L2 loss only\n  - **BSP**: MSE + fixed BSP loss (Î»=0.1)\n  - **SA-BSP (Per-bin)**: MSE + 32 adaptive per-bin weights (negated gradients)\n  - **SA-BSP (Global)**: MSE + 1 adaptive global weight (standard gradients)\n  - **SA-BSP (Hierarchical)**: MSE + 33 weights (1 global + 32 per-bin)\n- **Multi-loss comparison plots** showing training metrics\n- **Energy spectrum visualization** (E(k) vs wavenumber) to identify spectral bias\n- **Spectral bias quantification** with metrics and comparison plots\n- Compatible with Google Colab\n\n**Models available:**\n- `deeponet`: Branch-trunk architecture with SIREN activation (~235K params)\n- `fno`: Fourier Neural Operator (~261K params)\n- `unet`: Encoder-decoder with skip connections (~249K params)\n\n**SA-PINNs Implementation:**\nUses saddle-point optimization with negated gradients to automatically emphasize difficult frequency bins and optimize loss weighting."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0: Force Reload Modules\n",
    "\n",
    "Run this cell to reload all project modules after code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload of all modules\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Get list of all loaded modules from the project\n",
    "modules_to_reload = []\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if any(x in module_name for x in ['src.', 'configs.']):\n",
    "        modules_to_reload.append(module_name)\n",
    "\n",
    "# Remove modules from sys.modules to force reload\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "print(f\"âœ“ Cleared {len(modules_to_reload)} cached modules\")\n",
    "print(\"  Run Cell 1 to reimport all modules with latest code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports (Colab-Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're in /content\n",
    "try:\n",
    "    os.chdir('/content')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Clone repository if running in Colab\n",
    "repo_path = Path('/content/local')\n",
    "if not repo_path.exists():\n",
    "    print(\"ðŸ“¥ Cloning repository...\")\n",
    "    !git clone https://github.com/maximbeekenkamp/local.git\n",
    "    print(\"âœ… Repository cloned\")\n",
    "else:\n",
    "    print(\"ðŸ“¥ Updating repository...\")\n",
    "    !git -C /content/local pull\n",
    "    print(\"âœ… Repository updated\")\n",
    "\n",
    "# Change to repo directory\n",
    "try:\n",
    "    os.chdir('/content/local')\n",
    "    print(f\"âœ… Changed to: {os.getcwd()}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\nðŸ“¦ Installing dependencies...\")\n",
    "!pip install -r requirements.txt -q\n",
    "print(\"âœ… Dependencies installed\")\n",
    "\n",
    "# Standard imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Project imports\n",
    "from src.core.data_processing.cdon_dataset import CDONDataset\n",
    "from src.core.data_processing.cdon_transforms import CDONNormalization\n",
    "from src.core.models.model_factory import create_model\n",
    "from src.core.training.simple_trainer import SimpleTrainer\n",
    "from configs.training_config import TrainingConfig\n",
    "\n",
    "print(\"\\nâœ“ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Real CDON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project root\n",
    "project_root = Path.cwd()\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = project_root / 'CDONData'\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# Create normalization object (required by CDONDataset)\n",
    "stats_path = project_root / 'configs' / 'cdon_stats.json'\n",
    "print(f\"Loading stats from: {stats_path}\")\n",
    "normalizer = CDONNormalization(stats_path=str(stats_path))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CDONDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    split='train',\n",
    "    normalize=normalizer\n",
    ")\n",
    "\n",
    "val_dataset = CDONDataset(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    split='test',\n",
    "    normalize=normalizer\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Data loaded successfully\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Val samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Inspect a sample\n",
    "sample_input, sample_target = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "print(f\"  Input: {sample_input.shape}\")\n",
    "print(f\"  Target: {sample_target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Choose Model Architecture\n",
    "\n",
    "**Change `MODEL_ARCH` to try different models:**\n",
    "- `'deeponet'`: Branch-trunk architecture with SIREN activation\n",
    "- `'fno'`: Fourier Neural Operator\n",
    "- `'unet'`: U-Net encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model architecture\n",
    "MODEL_ARCH = 'deeponet'  # Options: 'deeponet', 'fno', 'unet'\n",
    "\n",
    "model = create_model(MODEL_ARCH)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"âœ“ Created {MODEL_ARCH.upper()} model\")\n",
    "print(f\"  Parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4: Initialize Results Storage\n\nWe'll train with all 5 loss types sequentially and store results for comparison:\n- **BASELINE**: Relative L2 loss only\n- **BSP**: MSE + fixed BSP loss (Î»=0.1)\n- **SA-BSP-PERBIN**: MSE + 32 adaptive per-bin weights (negated gradients)\n- **SA-BSP-GLOBAL**: MSE + 1 adaptive global weight (standard gradients)\n- **SA-BSP-HIERARCHICAL**: MSE + 33 weights (1 global + 32 per-bin, mixed gradients)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import loss configurations\nfrom configs.loss_config import (\n    BASELINE_CONFIG, \n    BSP_CONFIG, \n    SA_BSP_PERBIN_CONFIG,\n    SA_BSP_GLOBAL_CONFIG,\n    SA_BSP_HIERARCHICAL_CONFIG\n)\nfrom src.core.evaluation.loss_factory import create_loss\n\n# Loss configuration map\nloss_config_map = {\n    'baseline': BASELINE_CONFIG,\n    'bsp': BSP_CONFIG,\n    'sa-bsp-perbin': SA_BSP_PERBIN_CONFIG,\n    'sa-bsp-global': SA_BSP_GLOBAL_CONFIG,\n    'sa-bsp-hierarchical': SA_BSP_HIERARCHICAL_CONFIG\n}\n\n# Storage dictionaries for results from all loss types\nall_training_results = {}  # Key: f\"{MODEL_ARCH}_{loss_type}\"\nall_trainers = {}\ntrained_models = {}\n\nprint(\"âœ“ Storage initialized for multi-loss training\")\nprint(\"\\nWill train with 5 loss types:\")\nprint(\"  1. BASELINE:\", BASELINE_CONFIG.description)\nprint(\"  2. BSP:\", BSP_CONFIG.description)\nprint(\"  3. SA-BSP-PERBIN:\", SA_BSP_PERBIN_CONFIG.description)\nprint(\"  4. SA-BSP-GLOBAL:\", SA_BSP_GLOBAL_CONFIG.description)\nprint(\"  5. SA-BSP-HIERARCHICAL:\", SA_BSP_HIERARCHICAL_CONFIG.description)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5: Sequential Training with All Loss Types\n\nTrain the same model architecture with all 5 loss functions sequentially:\n1. **BASELINE** - Pure MSE baseline\n2. **BSP** - Fixed spectral loss\n3. **SA-BSP-PERBIN** - 32 adaptive weights (emphasize hard bins)\n4. **SA-BSP-GLOBAL** - 1 adaptive weight (balance MSE/BSP)\n5. **SA-BSP-HIERARCHICAL** - 33 adaptive weights (combined approach)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train with all 5 loss types sequentially\nloss_types_to_train = ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']\n\nfor LOSS_TYPE in loss_types_to_train:\n    print(f\"\\n{'='*70}\")\n    print(f\"Training {MODEL_ARCH.upper()} with {LOSS_TYPE.upper()} Loss\")\n    print(f\"{'='*70}\\n\")\n    \n    # Select loss configuration\n    selected_loss_config = loss_config_map[LOSS_TYPE]\n    print(f\"Loss config: {selected_loss_config.description}\")\n    \n    # Create loss function\n    criterion = create_loss(selected_loss_config)\n    print(f\"âœ“ Loss function created: {type(criterion).__name__}\")\n    \n    # Create FRESH model for this loss type (important!)\n    model_for_loss = create_model(MODEL_ARCH)\n    num_params = sum(p.numel() for p in model_for_loss.parameters() if p.requires_grad)\n    print(f\"âœ“ Fresh model created ({num_params:,} parameters)\")\n    \n    # Create training config\n    # Select optimizer based on architecture\n    # FNO has complex-valued Fourier layers incompatible with SOAP\n    optimizer_type = 'adam' if MODEL_ARCH == 'fno' else 'soap'\n    \n    config = TrainingConfig(\n        num_epochs=50,\n        learning_rate=1e-3,\n        optimizer_type=optimizer_type,  # Adam for FNO, SOAP for others\n        batch_size=BATCH_SIZE,\n        weight_decay=1e-4,\n        scheduler_type='cosine',\n        cosine_eta_min=1e-6,\n        eval_metrics=['field_error', 'spectrum_error'],\n        eval_frequency=1,\n        checkpoint_dir=f'checkpoints/{MODEL_ARCH}_{LOSS_TYPE}',\n        save_best=False,\n        save_latest=False,\n        device='cuda' if torch.cuda.is_available() else 'cpu',\n        num_workers=2,\n        verbose=True\n    )\n    \n    # Create trainer\n    trainer = SimpleTrainer(\n        model=model_for_loss,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config,\n        loss_config=selected_loss_config,\n        experiment_name=f'{MODEL_ARCH}_{LOSS_TYPE}'\n    )\n    \n    print(f\"âœ“ Trainer initialized\")\n    print(f\"  Device: {trainer.device}\")\n    print(f\"  Optimizer: {type(trainer.optimizer).__name__}\")\n    \n    # Check for weight optimizer (SA-BSP variants only)\n    if 'sa-bsp' in LOSS_TYPE:\n        if trainer.weight_optimizer is not None:\n            adapt_mode = trainer.adapt_mode\n            print(f\"  Weight optimizer: âœ“ Created for SA-BSP ({adapt_mode} mode)\")\n        else:\n            print(f\"  âš  WARNING: SA-BSP but no weight_optimizer!\")\n    \n    print(f\"\\nðŸš€ Starting training...\\n\")\n    \n    # Train\n    results = trainer.train()\n    \n    # Store results\n    key = f\"{MODEL_ARCH}_{LOSS_TYPE}\"\n    all_training_results[key] = results\n    all_trainers[key] = trainer\n    trained_models[key] = model_for_loss\n    \n    print(f\"\\nâœ… {LOSS_TYPE.upper()} training complete!\")\n    print(f\"   Best val loss: {results['best_val_loss']:.6f}\")\n    print(f\"   Final val loss: {results['val_history'][-1]['loss']:.6f}\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"ALL TRAINING COMPLETE!\")\nprint(f\"{'='*70}\")\nprint(f\"Trained {len(all_training_results)} models with different loss functions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Multi-Loss Training Comparison\n",
    "\n",
    "Compare training metrics across all 3 loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create multi-loss comparison plots\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Color scheme for loss types\ncolors = {\n    'baseline': '#1f77b4',      # Blue\n    'bsp': '#ff7f0e',            # Orange\n    'sa-bsp-perbin': '#2ca02c',  # Green\n    'sa-bsp-global': '#d62728',  # Red\n    'sa-bsp-hierarchical': '#9467bd'  # Purple\n}\nlinestyles = {\n    'baseline': '-', \n    'bsp': '--', \n    'sa-bsp-perbin': '-.', \n    'sa-bsp-global': ':', \n    'sa-bsp-hierarchical': '-'\n}\nmarkers = {\n    'baseline': 'o', \n    'bsp': 's', \n    'sa-bsp-perbin': '^', \n    'sa-bsp-global': 'D', \n    'sa-bsp-hierarchical': 'v'\n}\n\nfor loss_type in ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    results = all_training_results[key]\n    \n    # Extract metrics\n    val_losses = [h['loss'] for h in results['val_history']]\n    val_field_errors = [h['field_error'] for h in results['val_history']]\n    val_spectrum_errors = [h['spectrum_error'] for h in results['val_history']]\n    epochs = range(1, len(val_losses) + 1)\n    \n    # Create label with short name\n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-hierarchical': 'SA-BSP (Hier.)'\n    }\n    label = label_map[loss_type]\n    \n    # Plot on all 3 axes\n    axes[0].plot(epochs, val_losses, label=label, \n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n    \n    axes[1].plot(epochs, val_field_errors, label=label,\n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n    \n    axes[2].plot(epochs, val_spectrum_errors, label=label,\n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n\n# Configure axes\naxes[0].set_xlabel('Epoch', fontsize=12)\naxes[0].set_ylabel('Validation Loss', fontsize=12)\naxes[0].set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\naxes[0].legend(fontsize=9, loc='best')\naxes[0].grid(True, alpha=0.3)\n\naxes[1].set_xlabel('Epoch', fontsize=12)\naxes[1].set_ylabel('Field Error', fontsize=12)\naxes[1].set_title('Field Error (Real Space)', fontsize=14, fontweight='bold')\naxes[1].legend(fontsize=9, loc='best')\naxes[1].grid(True, alpha=0.3)\n\naxes[2].set_xlabel('Epoch', fontsize=12)\naxes[2].set_ylabel('Spectrum Error', fontsize=12)\naxes[2].set_title('Spectrum Error (Frequency Space)', fontsize=14, fontweight='bold')\naxes[2].legend(fontsize=9, loc='best')\naxes[2].grid(True, alpha=0.3)\n\nplt.suptitle(f'{MODEL_ARCH.upper()}: Loss Function Comparison (5 Variants)', \n             fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# Print final metrics table\nprint(f\"\\n{'='*70}\")\nprint(\"Final Metrics Summary\")\nprint(f\"{'='*70}\")\nprint(f\"{'Loss Type':<25} {'Val Loss':<12} {'Field Error':<15} {'Spectrum Error':<15}\")\nprint(\"-\"*70)\n\nfor loss_type in ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    results = all_training_results[key]\n    final_val = results['val_history'][-1]\n    \n    label = loss_type.upper()\n    print(f\"{label:<25} {final_val['loss']:<12.6f} \"\n          f\"{final_val['field_error']:<15.6f} {final_val['spectrum_error']:<15.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Spectral Bias Visualization (Energy Spectrum)\n",
    "\n",
    "Visualize E(k) vs wavenumber to identify spectral bias in trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch.fft as fft\n\ndef compute_energy_spectrum(signal, n_bins=32):\n    \"\"\"\n    Compute time-averaged energy spectrum E(k) vs wavenumber.\n    \n    Args:\n        signal: [batch, channels, timesteps] tensor\n        n_bins: Number of wavenumber bins\n    \n    Returns:\n        wavenumbers: array of wavenumber bin centers\n        energy: E(k) energy spectrum values\n    \"\"\"\n    # FFT along time dimension\n    fft_signal = fft.rfft(signal, dim=-1)  # [B, C, freq]\n    \n    # Compute power: |FFT|^2\n    power = torch.abs(fft_signal) ** 2  # [B, C, freq]\n    \n    # Average over batch and channels\n    power_avg = power.mean(dim=(0, 1))  # [freq]\n    \n    # Create wavenumbers (k = 1, 2, ..., N)\n    n_freq = power_avg.shape[0]\n    wavenumbers = torch.arange(1, n_freq + 1, dtype=torch.float32)\n    \n    # Bin the frequencies into n_bins\n    bin_edges = torch.linspace(0, n_freq, n_bins + 1)\n    binned_energy = []\n    binned_k = []\n    \n    for i in range(n_bins):\n        start_idx = int(bin_edges[i])\n        end_idx = int(bin_edges[i + 1])\n        \n        if end_idx > start_idx:\n            # Average energy in this bin\n            bin_energy = power_avg[start_idx:end_idx].mean().item()\n            # Bin center wavenumber\n            bin_k = wavenumbers[start_idx:end_idx].mean().item()\n            \n            binned_energy.append(bin_energy)\n            binned_k.append(bin_k)\n    \n    return np.array(binned_k), np.array(binned_energy)\n\n\n# Get validation batch for energy spectrum analysis\nprint(\"Computing energy spectra for all trained models...\")\nval_input, val_target = next(iter(val_loader))\n\n# Move to device for inference\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nval_input = val_input.to(device)\nval_target = val_target.to(device)\n\n# Compute ground truth spectrum\nk_true, E_true = compute_energy_spectrum(val_target)\n\n# Compute spectrum for each trained model\nspectra = {}\nspectra['True'] = (k_true, E_true)\n\nfor loss_type in ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    model_trained = trained_models[key]\n    model_trained.eval()\n    model_trained.to(device)\n    \n    with torch.no_grad():\n        pred = model_trained(val_input)\n    \n    k_pred, E_pred = compute_energy_spectrum(pred)\n    \n    # Create display label\n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-hierarchical': 'SA-BSP (Hier.)'\n    }\n    spectra[f\"{MODEL_ARCH.upper()} + {label_map[loss_type]}\"] = (k_pred, E_pred)\n    \n    print(f\"  âœ“ {loss_type.upper()} spectrum computed\")\n\n# Plot energy spectrum\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Plot ground truth (black solid line with higher zorder to be on top)\nax.loglog(k_true, E_true, 'k-', linewidth=3, label='True', zorder=10)\n\n# Plot model predictions with consistent colors\ncolors_plot = {\n    'baseline': '#1f77b4',\n    'bsp': '#ff7f0e',\n    'sa-bsp-perbin': '#2ca02c',\n    'sa-bsp-global': '#d62728',\n    'sa-bsp-hierarchical': '#9467bd'\n}\n\nfor loss_type in ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']:\n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-hierarchical': 'SA-BSP (Hier.)'\n    }\n    label_key = f\"{MODEL_ARCH.upper()} + {label_map[loss_type]}\"\n    k, E = spectra[label_key]\n    \n    # Plot line\n    ax.loglog(k, E, color=colors_plot[loss_type], linewidth=2.5, \n             alpha=0.8, label=label_key, zorder=5)\n\n# Configure plot\nax.set_xlabel('Wavenumber', fontsize=14, fontweight='bold')\nax.set_ylabel('E(k)', fontsize=14, fontweight='bold')\nax.set_title(f'Time-Averaged Energy Spectrum Comparison\\n{MODEL_ARCH.upper()} Model (5 Loss Variants)', \n            fontsize=16, fontweight='bold')\nax.legend(fontsize=11, loc='best', framealpha=0.9)\nax.grid(True, alpha=0.3, which='both', linestyle='--')\n\n# Set nice axis limits\nax.set_xlim(k_true.min() * 0.9, k_true.max() * 1.1)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nâœ“ Energy spectrum plot complete\")\nprint(f\"  This plot shows spectral bias: deviation from ground truth at high wavenumbers\")\nprint(f\"  SA-BSP variants should show better high-frequency matching than baseline\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Spectral Bias Quantification\n",
    "\n",
    "Compute spectral bias metrics to quantify how well each model captures high-frequency content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.core.visualization.spectral_analysis import compute_spectral_bias_metric\n\nprint(\"=\"*70)\nprint(\"SPECTRAL BIAS METRICS\")\nprint(\"=\"*70)\nprint(\"\\nQuantifies how well each model captures different frequency ranges.\")\nprint(\"Spectral Bias Ratio = High Freq Error / Low Freq Error\")\nprint(\"  - Ratio > 2.0: Significant spectral bias (struggles with high frequencies)\")\nprint(\"  - Ratio > 1.5: Moderate spectral bias\")\nprint(\"  - Ratio â‰¤ 1.5: Low spectral bias (captures frequencies well)\")\nprint(\"=\"*70)\n\n# Compute metrics for each trained model\nspectral_metrics = {}\n\nfor loss_type in ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    model_trained = trained_models[key]\n    model_trained.eval()\n    model_trained.to(device)\n    \n    with torch.no_grad():\n        pred = model_trained(val_input)\n    \n    metrics = compute_spectral_bias_metric(pred.cpu(), val_target.cpu(), n_bins=32)\n    spectral_metrics[loss_type] = metrics\n    \n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-hierarchical': 'SA-BSP (Hier.)'\n    }\n    \n    print(f\"\\n{MODEL_ARCH.upper()} + {label_map[loss_type]}:\")\n    print(f\"  Low frequency error:   {metrics['low_freq_error']:.6f}\")\n    print(f\"  Mid frequency error:   {metrics['mid_freq_error']:.6f}\")\n    print(f\"  High frequency error:  {metrics['high_freq_error']:.6f}\")\n    print(f\"  Spectral bias ratio:   {metrics['spectral_bias_ratio']:.4f}\")\n    \n    # Interpretation\n    if metrics['spectral_bias_ratio'] > 2.0:\n        print(f\"  â†’ âš ï¸  SIGNIFICANT spectral bias detected!\")\n        print(f\"     Model struggles with high-frequency content\")\n    elif metrics['spectral_bias_ratio'] > 1.5:\n        print(f\"  â†’ âš¡ MODERATE spectral bias\")\n        print(f\"     Some difficulty with high frequencies\")\n    else:\n        print(f\"  â†’ âœ… LOW spectral bias\")\n        print(f\"     Model captures frequency content well\")\n\n# Create comparison visualization\nprint(f\"\\n{'='*70}\")\nprint(\"Spectral Bias Comparison\")\nprint(f\"{'='*70}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n\n# Bar plot 1: Frequency errors\nloss_types = ['baseline', 'bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-hierarchical']\nx = np.arange(len(loss_types))\nwidth = 0.25\n\nlow_errors = [spectral_metrics[lt]['low_freq_error'] for lt in loss_types]\nmid_errors = [spectral_metrics[lt]['mid_freq_error'] for lt in loss_types]\nhigh_errors = [spectral_metrics[lt]['high_freq_error'] for lt in loss_types]\n\nax1.bar(x - width, low_errors, width, label='Low Freq', color='#2ca02c', alpha=0.8)\nax1.bar(x, mid_errors, width, label='Mid Freq', color='#ff7f0e', alpha=0.8)\nax1.bar(x + width, high_errors, width, label='High Freq', color='#d62728', alpha=0.8)\n\nax1.set_xlabel('Loss Type', fontsize=12, fontweight='bold')\nax1.set_ylabel('Frequency Error', fontsize=12, fontweight='bold')\nax1.set_title('Frequency Range Errors', fontsize=14, fontweight='bold')\nax1.set_xticks(x)\nax1.set_xticklabels(['BASELINE', 'BSP', 'SA-Per', 'SA-Glob', 'SA-Hier'], rotation=15, ha='right')\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3, axis='y')\n\n# Bar plot 2: Spectral bias ratio\nbias_ratios = [spectral_metrics[lt]['spectral_bias_ratio'] for lt in loss_types]\ncolors_bars = [colors_plot[lt] for lt in loss_types]\n\nbars = ax2.bar(x, bias_ratios, color=colors_bars, alpha=0.8, edgecolor='black', linewidth=1.5)\n\n# Add threshold lines\nax2.axhline(y=2.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Significant bias threshold')\nax2.axhline(y=1.5, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='Moderate bias threshold')\n\nax2.set_xlabel('Loss Type', fontsize=12, fontweight='bold')\nax2.set_ylabel('Spectral Bias Ratio', fontsize=12, fontweight='bold')\nax2.set_title('Spectral Bias Ratio (High/Low)', fontsize=14, fontweight='bold')\nax2.set_xticks(x)\nax2.set_xticklabels(['BASELINE', 'BSP', 'SA-Per', 'SA-Glob', 'SA-Hier'], rotation=15, ha='right')\nax2.legend(fontsize=10, loc='upper right')\nax2.grid(True, alpha=0.3, axis='y')\n\n# Add value labels on bars\nfor i, (bar, ratio) in enumerate(zip(bars, bias_ratios)):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n            f'{ratio:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.suptitle(f'{MODEL_ARCH.upper()}: Spectral Bias Analysis (5 Loss Variants)', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*70}\")\nprint(\"âœ… Spectral bias analysis complete!\")\nprint(f\"{'='*70}\")\nprint(\"\\nKey Findings:\")\nprint(\"  â€¢ Baseline: Pure MSE - typically shows significant spectral bias\")\nprint(\"  â€¢ BSP: Fixed spectral loss - moderate improvement\")\nprint(\"  â€¢ SA-BSP (Per-bin): Adaptive per-bin weights - best for high-freq capture\")\nprint(\"  â€¢ SA-BSP (Global): Adaptive MSE/BSP balance - optimizes overall trade-off\")\nprint(\"  â€¢ SA-BSP (Hierarchical): Combined approach - most expressive\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n1. âœ“ Loading real CDON data with proper normalization\n2. âœ“ Creating neural operator models (DeepONet, FNO, UNet)\n3. âœ“ **Sequential training with all 5 loss functions**:\n   - **BASELINE**: Relative L2 loss only\n   - **BSP**: MSE + fixed BSP loss (Î»=0.1)\n   - **SA-BSP (Per-bin)**: MSE + 32 adaptive per-bin weights (negated gradients)\n   - **SA-BSP (Global)**: MSE + 1 adaptive global weight (standard gradients)\n   - **SA-BSP (Hierarchical)**: MSE + 33 weights (1 global + 32 per-bin, mixed gradients)\n4. âœ“ **Multi-loss comparison plots** showing training metrics\n5. âœ“ **Energy spectrum visualization** (E(k) vs wavenumber) to identify spectral bias\n6. âœ“ **Spectral bias quantification** with metrics and comparison plots\n\n**Key Results:**\n- All 5 loss types trained on the same model architecture\n- Direct comparison shows which loss function best mitigates spectral bias\n- Energy spectrum plot reveals how well each model captures high-frequency content\n- Quantitative metrics identify spectral bias ratio for each approach\n\n**SA-PINNs Implementation:**\n- **Per-bin mode**: Uses negated gradients to emphasize difficult frequency bins\n- **Global mode**: Uses standard gradients to balance MSE/BSP trade-off\n- **Hierarchical mode**: Combines both approaches with mixed gradient strategies\n\n**Experiment with different configurations:**\n- **Cell 0**: Run to force reload modules after code changes\n- **Cell 3**: Change `MODEL_ARCH` to try different models ('deeponet', 'fno', 'unet')\n- **Cell 5**: Adjust hyperparameters (epochs, learning rate, etc.) in TrainingConfig\n- Run all cells sequentially to train and compare all 5 loss types automatically!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}