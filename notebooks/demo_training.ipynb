{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Neural Operator Training Demo: CDON Dataset\n\nThis notebook demonstrates end-to-end training of neural operator models (DeepONet, FNO, UNet) on the CDON dataset.\n\n**Features:**\n- Trains on **real CDON data**\n- **Sequential training with all 6 loss functions**:\n  - **BASELINE**: Relative L2 loss only (baseline MSE)\n  - **BSP**: MSE + fixed BSP loss with k¬≤ weighting\n  - **Log-BSP**: MSE + BSP with log‚ÇÅ‚ÇÄ spectral energies (uniform Œª_k weighting)\n  - **SA-BSP (Per-bin)**: MSE + 32 adaptive per-bin weights (negated gradients for frequency emphasis)\n  - **SA-BSP (Global)**: MSE + 2 adaptive weights (w_mse + w_bsp) for MSE/BSP balance\n  - **SA-BSP (Combined)**: MSE + 34 weights (w_mse + w_bsp + 32 per-bin) with full competitive dynamics\n- **Multi-loss comparison plots** showing training metrics\n- **Energy spectrum visualization** (E(k) vs wavenumber) to identify spectral bias\n- **Spectral bias quantification** with metrics and comparison plots\n- Compatible with Google Colab\n\n**Models available:**\n- `deeponet`: Branch-trunk architecture with SIREN activation (~235K params)\n- `fno`: Fourier Neural Operator (~261K params)\n- `unet`: Encoder-decoder with skip connections (~249K params)\n\n**SA-PINNs Implementation:**\nUses saddle-point optimization with negated gradients (gradient ascent on loss) to enable competitive dynamics. This automatically emphasizes difficult frequency bins and finds optimal loss balance through min-max optimization."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0: Force Reload Modules\n",
    "\n",
    "Run this cell to reload all project modules after code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload of all modules\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Get list of all loaded modules from the project\n",
    "modules_to_reload = []\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if any(x in module_name for x in ['src.', 'configs.']):\n",
    "        modules_to_reload.append(module_name)\n",
    "\n",
    "# Remove modules from sys.modules to force reload\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "print(f\"‚úì Cleared {len(modules_to_reload)} cached modules\")\n",
    "print(\"  Run Cell 1 to reimport all modules with latest code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Imports (Colab-Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're in /content\n",
    "try:\n",
    "    os.chdir('/content')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Clone repository if running in Colab\n",
    "repo_path = Path('/content/local')\n",
    "if not repo_path.exists():\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone https://github.com/maximbeekenkamp/local.git\n",
    "    print(\"‚úÖ Repository cloned\")\n",
    "else:\n",
    "    print(\"üì• Updating repository...\")\n",
    "    !git -C /content/local pull\n",
    "    print(\"‚úÖ Repository updated\")\n",
    "\n",
    "# Change to repo directory\n",
    "try:\n",
    "    os.chdir('/content/local')\n",
    "    print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\nüì¶ Installing dependencies...\")\n",
    "!pip install -r requirements.txt -q\n",
    "print(\"‚úÖ Dependencies installed\")\n",
    "\n",
    "# Standard imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Project imports\n",
    "from src.core.data_processing.cdon_dataset import CDONDataset\n",
    "from src.core.data_processing.cdon_transforms import CDONNormalization\n",
    "from src.core.models.model_factory import create_model\n",
    "from src.core.training.simple_trainer import SimpleTrainer\n",
    "from configs.training_config import TrainingConfig\n",
    "\n",
    "print(\"\\n‚úì Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Real CDON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get project root\nproject_root = Path.cwd()\nprint(f\"Project root: {project_root}\")\n\n# Data directory\nDATA_DIR = project_root / 'CDONData'\nprint(f\"Data directory: {DATA_DIR}\")\n\n# Create normalization object (required by CDONDataset)\nstats_path = project_root / 'configs' / 'cdon_stats.json'\nprint(f\"Loading stats from: {stats_path}\")\nnormalizer = CDONNormalization(stats_path=str(stats_path))\n\n# Create datasets with optional causal padding\ntrain_dataset = CDONDataset(\n    data_dir=str(DATA_DIR),\n    split='train',\n    normalize=normalizer,\n    use_causal_padding=USE_CAUSAL_PADDING,  # NEW: Apply zero-padding if enabled\n    signal_length=4000\n)\n\nval_dataset = CDONDataset(\n    data_dir=str(DATA_DIR),\n    split='test',\n    normalize=normalizer,\n    use_causal_padding=USE_CAUSAL_PADDING,  # NEW: Apply zero-padding if enabled\n    signal_length=4000\n)\n\n# Create dataloaders\nBATCH_SIZE = 16\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"\\n‚úì Data loaded successfully\")\nprint(f\"  Train samples: {len(train_dataset)}\")\nprint(f\"  Val samples: {len(val_dataset)}\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\n\n# Inspect a sample\nsample_input, sample_target = train_dataset[0]\nprint(f\"\\nSample shapes:\")\nprint(f\"  Input: {sample_input.shape}\")\nprint(f\"  Target: {sample_target.shape}\")\n\nif USE_CAUSAL_PADDING:\n    expected_input_len = 4000 + (4000 - 1)  # signal_length + padding\n    if sample_input.shape[-1] == expected_input_len:\n        print(f\"  ‚úì Causal padding applied correctly (input length: {expected_input_len})\")\n    else:\n        print(f\"  ‚ö† Warning: Expected input length {expected_input_len}, got {sample_input.shape[-1]}\")"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# NEW FEATURES CONFIGURATION\n# ============================================================================\n\n# 1. CAUSALITY: Zero-padding preprocessing (Reference CausalityDeepONet)\nUSE_CAUSAL_PADDING = True  # ENABLED BY DEFAULT (matches reference)\n# Set to False to disable causal padding (standard preprocessing)\n# NOTE: DeepONet uses per-timestep windowing (handled in preprocessing_utils.py)\n#       UNet/FNO use simple left-padding (enabled here)\n\n# 2. DEEPONET ACTIVATION: Choose activation function\nDEEPONET_ACTIVATION = 'requ'  # Options: 'requ' (default), 'tanh', 'relu', 'siren'\n# 'requ' = ReLU¬≤ (reference default, smooth gradients)\n# 'tanh' = Stable for operator learning\n# 'relu' = Standard ReLU\n# 'siren' = Sinusoidal activation (requires siren-pytorch)\n\n# 3. PENALTY LOSS: Optional inverse-variance weighting\nUSE_PENALTY_LOSS = False  # Set to True to enable penalty weighting\nPENALTY_EPSILON = 1e-8     # Numerical stability for penalty\nPENALTY_PER_SAMPLE = True  # Per-sample (True) or global (False) penalty\n\nprint(\"‚úì New features configured:\")\nprint(f\"  Causal padding:     {'ENABLED' if USE_CAUSAL_PADDING else 'DISABLED'} (default: ENABLED)\")\nprint(f\"  DeepONet activation: {DEEPONET_ACTIVATION.upper()} (default: REQU)\")\nprint(f\"  Penalty loss:       {'ENABLED' if USE_PENALTY_LOSS else 'DISABLED'} (default: DISABLED)\")\nif USE_PENALTY_LOSS:\n    print(f\"    - Epsilon:        {PENALTY_EPSILON}\")\n    print(f\"    - Per-sample:     {PENALTY_PER_SAMPLE}\")\nprint()\n\n# These settings will be applied in subsequent cells\nprint(\"üìù NOTE:\")\nif USE_CAUSAL_PADDING:\n    print(\"  ‚Üí Zero-padding ENABLED (matches reference CausalityDeepONet)\")\n    print(\"  ‚Üí Inputs will be left-padded: [1, 4000] ‚Üí [1, 7999]\")\n    print(\"  ‚Üí Outputs remain unchanged: [1, 4000]\")\nelse:\n    print(\"  ‚Üí Standard preprocessing (inputs: [1, 4000], outputs: [1, 4000])\")\n\nif USE_PENALTY_LOSS:\n    print(\"  ‚Üí Penalty weighting will be applied to all loss functions\")\n    print(f\"    Formula: loss *= 1 / (max(abs(target))¬≤ + {PENALTY_EPSILON})\")\n    \nprint(f\"  ‚Üí DeepONet will use {DEEPONET_ACTIVATION.upper()} activation\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Choose model architecture\nMODEL_ARCH = 'deeponet'  # Options: 'deeponet', 'fno', 'unet'\n\n# Create model with optional DeepONet activation\nif MODEL_ARCH == 'deeponet':\n    model = create_model(MODEL_ARCH, config={'activation': DEEPONET_ACTIVATION})\n    print(f\"‚úì Created {MODEL_ARCH.upper()} model with {DEEPONET_ACTIVATION.upper()} activation\")\nelse:\n    model = create_model(MODEL_ARCH)\n    print(f\"‚úì Created {MODEL_ARCH.upper()} model\")\n\nnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"  Parameters: {num_params:,}\")",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Choose Model Architecture\n",
    "\n",
    "**Change `MODEL_ARCH` to try different models:**\n",
    "- `'deeponet'`: Branch-trunk architecture with SIREN activation\n",
    "- `'fno'`: Fourier Neural Operator\n",
    "- `'unet'`: U-Net encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model architecture\n",
    "MODEL_ARCH = 'deeponet'  # Options: 'deeponet', 'fno', 'unet'\n",
    "\n",
    "model = create_model(MODEL_ARCH)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úì Created {MODEL_ARCH.upper()} model\")\n",
    "print(f\"  Parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4: Initialize Results Storage\n\nWe'll train with all 6 loss types sequentially and store results for comparison:\n- **BASELINE**: Relative L2 loss only (MSE baseline)\n- **BSP**: MSE + fixed BSP loss with k¬≤ weighting\n- **Log-BSP**: MSE + BSP with log‚ÇÅ‚ÇÄ spectral energies (uniform weighting)\n- **SA-BSP-PERBIN**: MSE + 32 adaptive per-bin weights (negated gradients for frequency emphasis)\n- **SA-BSP-GLOBAL**: 2 adaptive weights (w_mse + w_bsp) with negated gradients for MSE/BSP balance\n- **SA-BSP-COMBINED**: 34 weights (w_mse + w_bsp + 32 per-bin) with full competitive dynamics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import loss configurations\nfrom configs.loss_config import (\n    BASELINE_CONFIG, \n    BSP_CONFIG,\n    LOG_BSP_CONFIG,\n    SA_BSP_PERBIN_CONFIG,\n    SA_BSP_GLOBAL_CONFIG,\n    SA_BSP_COMBINED_CONFIG\n)\nfrom src.core.evaluation.loss_factory import create_loss\n\n# Loss configuration map\nloss_config_map = {\n    'baseline': BASELINE_CONFIG,\n    'bsp': BSP_CONFIG,\n    'log-bsp': LOG_BSP_CONFIG,\n    'sa-bsp-perbin': SA_BSP_PERBIN_CONFIG,\n    'sa-bsp-global': SA_BSP_GLOBAL_CONFIG,\n    'sa-bsp-combined': SA_BSP_COMBINED_CONFIG\n}\n\n# Storage dictionaries for results from all loss types\nall_training_results = {}  # Key: f\"{MODEL_ARCH}_{loss_type}\"\nall_trainers = {}\ntrained_models = {}\n\nprint(\"‚úì Storage initialized for multi-loss training\")\nprint(\"\\nWill train with 6 loss types:\")\nprint(\"  1. BASELINE:\", BASELINE_CONFIG.description)\nprint(\"  2. BSP:\", BSP_CONFIG.description)\nprint(\"  3. LOG-BSP:\", LOG_BSP_CONFIG.description)\nprint(\"  4. SA-BSP-PERBIN:\", SA_BSP_PERBIN_CONFIG.description)\nprint(\"  5. SA-BSP-GLOBAL:\", SA_BSP_GLOBAL_CONFIG.description)\nprint(\"  6. SA-BSP-COMBINED:\", SA_BSP_COMBINED_CONFIG.description)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5: Sequential Training with All Loss Types\n\nTrain the same model architecture with all 6 loss functions sequentially:\n1. **BASELINE** - Pure MSE baseline\n2. **BSP** - Fixed spectral loss with k¬≤ weighting\n3. **Log-BSP** - Spectral loss with log‚ÇÅ‚ÇÄ energies and uniform weighting\n4. **SA-BSP-PERBIN** - 32 adaptive weights (emphasize hard frequency bins)\n5. **SA-BSP-GLOBAL** - 2 adaptive weights (learn MSE/BSP balance)\n6. **SA-BSP-COMBINED** - 34 adaptive weights (full competitive dynamics)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train with all 6 loss types sequentially\nloss_types_to_train = ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']\n\nfor LOSS_TYPE in loss_types_to_train:\n    print(f\"\\n{'='*70}\")\n    print(f\"Training {MODEL_ARCH.upper()} with {LOSS_TYPE.upper()} Loss\")\n    print(f\"{'='*70}\\n\")\n    \n    # Select loss configuration\n    selected_loss_config = loss_config_map[LOSS_TYPE]\n    print(f\"Loss config: {selected_loss_config.description}\")\n    \n    # Create loss function\n    criterion = create_loss(selected_loss_config)\n    print(f\"‚úì Loss function created: {type(criterion).__name__}\")\n    \n    # Create FRESH model for this loss type (important!)\n    model_for_loss = create_model(MODEL_ARCH)\n    num_params = sum(p.numel() for p in model_for_loss.parameters() if p.requires_grad)\n    print(f\"‚úì Fresh model created ({num_params:,} parameters)\")\n    \n    # Create training config\n    # Select optimizer based on architecture\n    # FNO has complex-valued Fourier layers incompatible with SOAP\n    optimizer_type = 'adam' if MODEL_ARCH == 'fno' else 'soap'\n    \n    config = TrainingConfig(\n        num_epochs=50,\n        learning_rate=1e-3,\n        optimizer_type=optimizer_type,  # Adam for FNO, SOAP for others\n        batch_size=BATCH_SIZE,\n        weight_decay=1e-4,\n        scheduler_type='cosine',\n        cosine_eta_min=1e-6,\n        eval_metrics=['field_error', 'spectrum_error'],\n        eval_frequency=1,\n        checkpoint_dir=f'checkpoints/{MODEL_ARCH}_{LOSS_TYPE}',\n        save_best=False,\n        save_latest=False,\n        device='cuda' if torch.cuda.is_available() else 'cpu',\n        num_workers=2,\n        verbose=True\n    )\n    \n    # Create trainer\n    trainer = SimpleTrainer(\n        model=model_for_loss,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config,\n        loss_config=selected_loss_config,\n        experiment_name=f'{MODEL_ARCH}_{LOSS_TYPE}'\n    )\n    \n    print(f\"‚úì Trainer initialized\")\n    print(f\"  Device: {trainer.device}\")\n    print(f\"  Optimizer: {type(trainer.optimizer).__name__}\")\n    \n    # Check for weight optimizer (SA-BSP variants only)\n    if 'sa-bsp' in LOSS_TYPE:\n        if trainer.weight_optimizer is not None:\n            adapt_mode = trainer.adapt_mode\n            print(f\"  Weight optimizer: ‚úì Created for SA-BSP ({adapt_mode} mode)\")\n        else:\n            print(f\"  ‚ö† WARNING: SA-BSP but no weight_optimizer!\")\n    \n    print(f\"\\nüöÄ Starting training...\\n\")\n    \n    # Train\n    results = trainer.train()\n    \n    # Store results\n    key = f\"{MODEL_ARCH}_{LOSS_TYPE}\"\n    all_training_results[key] = results\n    all_trainers[key] = trainer\n    trained_models[key] = model_for_loss\n    \n    print(f\"\\n‚úÖ {LOSS_TYPE.upper()} training complete!\")\n    print(f\"   Best val loss: {results['best_val_loss']:.6f}\")\n    print(f\"   Final val loss: {results['val_history'][-1]['loss']:.6f}\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"ALL TRAINING COMPLETE!\")\nprint(f\"{'='*70}\")\nprint(f\"Trained {len(all_training_results)} models with different loss functions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 6: Multi-Loss Training Comparison\n\nCompare training metrics across all 6 loss functions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create multi-loss comparison plots\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Color scheme for loss types\ncolors = {\n    'baseline': '#1f77b4',       # Blue\n    'bsp': '#ff7f0e',             # Orange\n    'log-bsp': '#2ca02c',         # Green\n    'sa-bsp-perbin': '#d62728',   # Red\n    'sa-bsp-global': '#9467bd',   # Purple\n    'sa-bsp-combined': '#17becf'  # Cyan\n}\nlinestyles = {\n    'baseline': '-', \n    'bsp': '--', \n    'log-bsp': '-.', \n    'sa-bsp-perbin': ':', \n    'sa-bsp-global': '-',\n    'sa-bsp-combined': '--'\n}\nmarkers = {\n    'baseline': 'o', \n    'bsp': 's', \n    'log-bsp': '^', \n    'sa-bsp-perbin': 'D', \n    'sa-bsp-global': 'v',\n    'sa-bsp-combined': 'p'\n}\n\nfor loss_type in ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    results = all_training_results[key]\n    \n    # Extract metrics\n    val_losses = [h['loss'] for h in results['val_history']]\n    val_field_errors = [h['field_error'] for h in results['val_history']]\n    val_spectrum_errors = [h['spectrum_error'] for h in results['val_history']]\n    epochs = range(1, len(val_losses) + 1)\n    \n    # Create label with short name\n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'log-bsp': 'Log-BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-combined': 'SA-BSP (Combined)'\n    }\n    label = label_map[loss_type]\n    \n    # Plot on all 3 axes\n    axes[0].plot(epochs, val_losses, label=label, \n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n    \n    axes[1].plot(epochs, val_field_errors, label=label,\n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n    \n    axes[2].plot(epochs, val_spectrum_errors, label=label,\n                color=colors[loss_type], linestyle=linestyles[loss_type],\n                linewidth=2, alpha=0.9, marker=markers[loss_type], markersize=4, markevery=5)\n\n# Configure axes with LOG SCALE on y-axis\naxes[0].set_xlabel('Epoch', fontsize=12)\naxes[0].set_ylabel('Validation Loss', fontsize=12)\naxes[0].set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\naxes[0].set_yscale('log')  # LOG SCALE\naxes[0].legend(fontsize=9, loc='best')\naxes[0].grid(True, alpha=0.3, which='both')\n\naxes[1].set_xlabel('Epoch', fontsize=12)\naxes[1].set_ylabel('Field Error', fontsize=12)\naxes[1].set_title('Field Error (Real Space)', fontsize=14, fontweight='bold')\naxes[1].set_yscale('log')  # LOG SCALE\naxes[1].legend(fontsize=9, loc='best')\naxes[1].grid(True, alpha=0.3, which='both')\n\naxes[2].set_xlabel('Epoch', fontsize=12)\naxes[2].set_ylabel('Spectrum Error', fontsize=12)\naxes[2].set_title('Spectrum Error (Frequency Space)', fontsize=14, fontweight='bold')\naxes[2].set_yscale('log')  # LOG SCALE\naxes[2].legend(fontsize=9, loc='best')\naxes[2].grid(True, alpha=0.3, which='both')\n\nplt.suptitle(f'{MODEL_ARCH.upper()}: Loss Function Comparison (6 Variants)', \n             fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# Print final metrics table\nprint(f\"\\n{'='*70}\")\nprint(\"Final Metrics Summary\")\nprint(f\"{'='*70}\")\nprint(f\"{'Loss Type':<25} {'Val Loss':<12} {'Field Error':<15} {'Spectrum Error':<15}\")\nprint(\"-\"*70)\n\nfor loss_type in ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    results = all_training_results[key]\n    final_val = results['val_history'][-1]\n    \n    label = loss_type.upper()\n    print(f\"{label:<25} {final_val['loss']:<12.6f} \"\n          f\"{final_val['field_error']:<15.6f} {final_val['spectrum_error']:<15.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Spectral Bias Visualization (Energy Spectrum)\n",
    "\n",
    "Visualize E(k) vs wavenumber to identify spectral bias in trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch.fft as fft\nfrom src.core.visualization.spectral_analysis import compute_unbinned_spectrum, compute_cached_true_spectrum\nfrom configs.visualization_config import SPECTRUM_CACHE_FILENAME, CACHE_DIR\n\n# Get validation batch for energy spectrum analysis\nprint(\"Computing energy spectra for all trained models...\")\n\n# Check if models have been trained\nif 'trained_models' not in globals() or len(trained_models) == 0:\n    print(\"\\n‚ö†Ô∏è  WARNING: No trained models found!\")\n    print(\"   Please run Cell 12 (training) first before running this cell.\")\n    print(\"   This cell requires the 'trained_models' dictionary to be populated.\\n\")\nelse:\n    print(f\"‚úì Found {len(trained_models)} trained models\")\n    print(f\"  Keys: {list(trained_models.keys())}\\n\")\n\nval_batch_input, val_batch_target = next(iter(val_loader))\n\n# Move to device for inference\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nval_batch_input = val_batch_input.to(device)\nval_batch_target = val_batch_target.to(device)\n\n# Compute ground truth spectrum with percentile-based uncertainty bands from cache\ncache_path = f'{CACHE_DIR}/{SPECTRUM_CACHE_FILENAME}'\nprint(f\"Loading true spectrum from cache: {cache_path}\")\ncached = np.load(cache_path)\nk_true = cached['unbinned_frequencies']  # Full FFT resolution (~2000 frequencies)\nE_true_median = cached['unbinned_energy_median']  # Median (50th percentile)\nE_true_p16 = cached['unbinned_energy_p16']        # Lower bound (16th percentile ‚âà -1œÉ)\nE_true_p84 = cached['unbinned_energy_p84']        # Upper bound (84th percentile ‚âà +1œÉ)\nprint(f\"‚úì True spectrum loaded ({len(k_true)} frequencies, unbinned)\")\nprint(f\"  Using percentile-based uncertainty bands (16th-84th ‚âà ¬±1œÉ)\")\n\n# Collect ALL validation predictions for uncertainty bands\nprint(\"\\nComputing unbinned spectra with percentile-based uncertainty bands for all models...\")\nspectra = {}\n\n# Store true spectrum with percentile uncertainty bounds\nspectra['True'] = {\n    'frequencies': k_true,\n    'energy_median': E_true_median,\n    'energy_p16': E_true_p16,\n    'energy_p84': E_true_p84\n}\n\nfor loss_type in ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    \n    # Check if model exists\n    if key not in trained_models:\n        print(f\"  ‚ö†Ô∏è  Skipping {loss_type.upper()}: model key '{key}' not found in trained_models\")\n        continue\n    \n    model_trained = trained_models[key]\n    model_trained.eval()\n    model_trained.to(device)\n    \n    try:\n        # Collect predictions from ALL validation batches for uncertainty bands\n        all_preds = []\n        print(f\"  Processing {loss_type.upper()}...\", end='')\n        \n        with torch.no_grad():\n            for val_input, _ in val_loader:\n                val_input = val_input.to(device)\n                pred = model_trained(val_input)\n                all_preds.append(pred.cpu())\n        \n        # Stack all predictions: [total_val_samples, C, T]\n        all_preds_tensor = torch.cat(all_preds, dim=0)\n        \n        # Compute unbinned spectrum with percentile-based uncertainty bands\n        k_pred, E_pred_median, E_pred_p16, E_pred_p84 = compute_unbinned_spectrum(all_preds_tensor)\n        \n        # Create display label\n        label_map = {\n            'baseline': 'BASELINE',\n            'bsp': 'BSP',\n            'log-bsp': 'Log-BSP',\n            'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n            'sa-bsp-global': 'SA-BSP (Global)',\n            'sa-bsp-combined': 'SA-BSP (Combined)'\n        }\n        spec_key = f\"{MODEL_ARCH.upper()} + {label_map[loss_type]}\"\n        \n        spectra[spec_key] = {\n            'frequencies': k_pred,\n            'energy_median': E_pred_median,\n            'energy_p16': E_pred_p16,\n            'energy_p84': E_pred_p84\n        }\n        \n        print(f\" ‚úì ({all_preds_tensor.shape[0]} samples)\")\n    except Exception as e:\n        print(f\" ‚ùå Error: {e}\")\n        continue\n\nprint(f\"\\n‚úì Spectra computed for {len(spectra)} entries with percentile-based uncertainty bands\\n\")\n\n# Plot energy spectrum with percentile-based uncertainty bands (safe for log scale!)\nfig, ax = plt.subplots(figsize=(14, 9))\n\n# Color scheme for loss types\ncolors_plot = {\n    'True': '#000000',  # Black for ground truth\n    'baseline': '#1f77b4',\n    'bsp': '#ff7f0e',\n    'log-bsp': '#2ca02c',\n    'sa-bsp-perbin': '#d62728',\n    'sa-bsp-global': '#9467bd',\n    'sa-bsp-combined': '#17becf'\n}\n\n# Plot ground truth with uncertainty band (black)\nif 'True' in spectra:\n    data = spectra['True']\n    k = data['frequencies']\n    E_median = data['energy_median']\n    E_p16 = data['energy_p16']\n    E_p84 = data['energy_p84']\n    \n    # Plot median line\n    ax.loglog(k, E_median, color=colors_plot['True'], linewidth=3, \n             label='True (Real Data)', zorder=10, alpha=0.9)\n    \n    # Plot percentile-based uncertainty band (16th-84th percentiles ‚âà ¬±1œÉ)\n    # These are GUARANTEED to be positive ‚Üí safe for log scale!\n    ax.fill_between(k, E_p16, E_p84,\n                     color=colors_plot['True'], alpha=0.15, zorder=9,\n                     label='True (16th-84th percentile)')\n\n# Plot model predictions with percentile-based uncertainty bands\nfor loss_type in ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']:\n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'log-bsp': 'Log-BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-combined': 'SA-BSP (Combined)'\n    }\n    label_key = f\"{MODEL_ARCH.upper()} + {label_map[loss_type]}\"\n    \n    # Check if spectrum exists before plotting\n    if label_key not in spectra:\n        print(f\"  ‚ö†Ô∏è  Skipping plot for {loss_type.upper()}: '{label_key}' not in spectra dictionary\")\n        continue\n    \n    data = spectra[label_key]\n    k = data['frequencies']\n    E_median = data['energy_median']\n    E_p16 = data['energy_p16']\n    E_p84 = data['energy_p84']\n    \n    color = colors_plot[loss_type]\n    \n    # Plot median line\n    ax.loglog(k, E_median, color=color, linewidth=2.5, \n             alpha=0.85, label=label_key, zorder=5)\n    \n    # Plot percentile-based uncertainty band (guaranteed positive for log scale)\n    ax.fill_between(k, E_p16, E_p84,\n                     color=color, alpha=0.12, zorder=4)\n\n# Configure plot\nax.set_xlabel('Frequency (normalized)', fontsize=14, fontweight='bold')\nax.set_ylabel('E(k) - Spectral Power', fontsize=14, fontweight='bold')\nax.set_title(f'Energy Spectrum Comparison with Percentile Uncertainty Bands\\n{MODEL_ARCH.upper()} Model (6 Loss Variants)', \n            fontsize=16, fontweight='bold')\nax.legend(fontsize=10, loc='best', framealpha=0.95, ncol=1)\nax.grid(True, alpha=0.3, which='both', linestyle='--')\n\n# Set nice axis limits\nax.set_xlim(k_true.min() * 0.9, k_true.max() * 1.1)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n‚úì Energy spectrum plot complete\")\nprint(f\"  ‚Ä¢ Unbinned spectrum: Full FFT resolution (~{len(k_true)} frequencies)\")\nprint(f\"  ‚Ä¢ Uncertainty bands: 16th-84th percentiles (‚âà ¬±1œÉ) across all validation samples\")\nprint(f\"  ‚Ä¢ Percentiles are ALWAYS positive ‚Üí safe for log-scale display!\")\nprint(f\"  ‚Ä¢ This visualization shows spectral bias: deviation from ground truth at high frequencies\")\nprint(f\"  ‚Ä¢ Log-BSP and SA-BSP variants should show better high-frequency matching than baseline\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Spectral Bias Quantification\n",
    "\n",
    "Compute spectral bias metrics to quantify how well each model captures high-frequency content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.core.visualization.spectral_analysis import compute_spectral_bias_metric\n\nprint(\"=\"*70)\nprint(\"SPECTRAL BIAS METRICS\")\nprint(\"=\"*70)\nprint(\"\\nQuantifies how well each model captures different frequency ranges.\")\nprint(\"Spectral Bias Ratio = High Freq Error / Low Freq Error\")\nprint(\"  - Ratio > 2.0: Significant spectral bias (struggles with high frequencies)\")\nprint(\"  - Ratio > 1.5: Moderate spectral bias\")\nprint(\"  - Ratio ‚â§ 1.5: Low spectral bias (captures frequencies well)\")\nprint(\"=\"*70)\n\n# Compute metrics for each trained model\nspectral_metrics = {}\n\nfor loss_type in ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']:\n    key = f\"{MODEL_ARCH}_{loss_type}\"\n    model_trained = trained_models[key]\n    model_trained.eval()\n    model_trained.to(device)\n    \n    with torch.no_grad():\n        pred = model_trained(val_input)\n    \n    metrics = compute_spectral_bias_metric(pred.cpu(), val_target.cpu(), n_bins=32)\n    spectral_metrics[loss_type] = metrics\n    \n    label_map = {\n        'baseline': 'BASELINE',\n        'bsp': 'BSP',\n        'log-bsp': 'Log-BSP',\n        'sa-bsp-perbin': 'SA-BSP (Per-bin)',\n        'sa-bsp-global': 'SA-BSP (Global)',\n        'sa-bsp-combined': 'SA-BSP (Combined)'\n    }\n    \n    print(f\"\\n{MODEL_ARCH.upper()} + {label_map[loss_type]}:\")\n    print(f\"  Low frequency error:   {metrics['low_freq_error']:.6f}\")\n    print(f\"  Mid frequency error:   {metrics['mid_freq_error']:.6f}\")\n    print(f\"  High frequency error:  {metrics['high_freq_error']:.6f}\")\n    print(f\"  Spectral bias ratio:   {metrics['spectral_bias_ratio']:.4f}\")\n    \n    # Interpretation\n    if metrics['spectral_bias_ratio'] > 2.0:\n        print(f\"  ‚Üí ‚ö†Ô∏è  SIGNIFICANT spectral bias detected!\")\n        print(f\"     Model struggles with high-frequency content\")\n    elif metrics['spectral_bias_ratio'] > 1.5:\n        print(f\"  ‚Üí ‚ö° MODERATE spectral bias\")\n        print(f\"     Some difficulty with high frequencies\")\n    else:\n        print(f\"  ‚Üí ‚úÖ LOW spectral bias\")\n        print(f\"     Model captures frequency content well\")\n\n# Create comparison visualization\nprint(f\"\\n{'='*70}\")\nprint(\"Spectral Bias Comparison\")\nprint(f\"{'='*70}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n\n# Bar plot 1: Frequency errors\nloss_types = ['baseline', 'bsp', 'log-bsp', 'sa-bsp-perbin', 'sa-bsp-global', 'sa-bsp-combined']\nx = np.arange(len(loss_types))\nwidth = 0.2\n\nlow_errors = [spectral_metrics[lt]['low_freq_error'] for lt in loss_types]\nmid_errors = [spectral_metrics[lt]['mid_freq_error'] for lt in loss_types]\nhigh_errors = [spectral_metrics[lt]['high_freq_error'] for lt in loss_types]\n\nax1.bar(x - width, low_errors, width, label='Low Freq', color='#2ca02c', alpha=0.8)\nax1.bar(x, mid_errors, width, label='Mid Freq', color='#ff7f0e', alpha=0.8)\nax1.bar(x + width, high_errors, width, label='High Freq', color='#d62728', alpha=0.8)\n\nax1.set_xlabel('Loss Type', fontsize=12, fontweight='bold')\nax1.set_ylabel('Frequency Error', fontsize=12, fontweight='bold')\nax1.set_title('Frequency Range Errors', fontsize=14, fontweight='bold')\nax1.set_yscale('log')  # LOG SCALE\nax1.set_xticks(x)\nax1.set_xticklabels(['BASE', 'BSP', 'Log-BSP', 'SA-Per', 'SA-Glob', 'SA-Comb'], rotation=15, ha='right')\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3, axis='y', which='both')\n\n# Bar plot 2: Spectral bias ratio\nbias_ratios = [spectral_metrics[lt]['spectral_bias_ratio'] for lt in loss_types]\ncolors_bars = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#17becf']\n\nbars = ax2.bar(x, bias_ratios, color=colors_bars, alpha=0.8, edgecolor='black', linewidth=1.5)\n\n# Add threshold lines\nax2.axhline(y=2.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Significant bias threshold')\nax2.axhline(y=1.5, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='Moderate bias threshold')\n\nax2.set_xlabel('Loss Type', fontsize=12, fontweight='bold')\nax2.set_ylabel('Spectral Bias Ratio', fontsize=12, fontweight='bold')\nax2.set_title('Spectral Bias Ratio (High/Low)', fontsize=14, fontweight='bold')\nax2.set_xticks(x)\nax2.set_xticklabels(['BASE', 'BSP', 'Log-BSP', 'SA-Per', 'SA-Glob', 'SA-Comb'], rotation=15, ha='right')\nax2.legend(fontsize=10, loc='upper right')\nax2.grid(True, alpha=0.3, axis='y')\n\n# Add value labels on bars\nfor i, (bar, ratio) in enumerate(zip(bars, bias_ratios)):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n            f'{ratio:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.suptitle(f'{MODEL_ARCH.upper()}: Spectral Bias Analysis (6 Loss Variants)', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n{'='*70}\")\nprint(\"‚úÖ Spectral bias analysis complete!\")\nprint(f\"{'='*70}\")\nprint(\"\\nKey Findings:\")\nprint(\"  ‚Ä¢ Baseline: Pure MSE - typically shows significant spectral bias\")\nprint(\"  ‚Ä¢ BSP: Fixed spectral loss with k¬≤ weighting - moderate improvement\")\nprint(\"  ‚Ä¢ Log-BSP: Log-domain spectral loss - addresses wide dynamic range\")\nprint(\"  ‚Ä¢ SA-BSP (Per-bin): Adaptive per-bin weights - emphasize hard frequencies\")\nprint(\"  ‚Ä¢ SA-BSP (Global): Adaptive MSE/BSP balance - optimize overall trade-off\")\nprint(\"  ‚Ä¢ SA-BSP (Combined): Full competitive dynamics - most expressive approach\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n1. ‚úì Loading real CDON data with proper normalization\n2. ‚úì Creating neural operator models (DeepONet, FNO, UNet)\n3. ‚úì **Sequential training with all 6 loss functions**:\n   - **BASELINE**: Relative L2 loss only (MSE baseline)\n   - **BSP**: MSE + fixed BSP loss with k¬≤ weighting\n   - **Log-BSP**: MSE + BSP with log‚ÇÅ‚ÇÄ spectral energies (uniform weighting)\n   - **SA-BSP (Per-bin)**: MSE + 32 adaptive per-bin weights (negated gradients for frequency emphasis)\n   - **SA-BSP (Global)**: MSE + 2 adaptive weights (w_mse + w_bsp, negated gradients for MSE/BSP balance)\n   - **SA-BSP (Combined)**: MSE + 34 weights (w_mse + w_bsp + 32 per-bin, all negated gradients for full competitive dynamics)\n4. ‚úì **Multi-loss comparison plots** showing training metrics\n5. ‚úì **Energy spectrum visualization** (E(k) vs wavenumber) to identify spectral bias\n6. ‚úì **Spectral bias quantification** with metrics and comparison plots\n\n**Key Results:**\n- All 6 loss types trained on the same model architecture\n- Direct comparison shows which loss function best mitigates spectral bias\n- Energy spectrum plot reveals how well each model captures high-frequency content\n- Quantitative metrics identify spectral bias ratio for each approach\n\n**SA-PINNs Implementation:**\n- **Per-bin mode**: Uses negated gradients (ascent) to emphasize difficult frequency bins\n- **Global mode**: Uses negated gradients (ascent) to learn optimal MSE/BSP balance via competitive dynamics\n- **Combined mode**: Full competitive dynamics with all weights (w_mse, w_bsp, and 32 per-bin) using negated gradients\n\n**Experiment with different configurations:**\n- **Cell 0**: Run to force reload modules after code changes\n- **Cell 3**: Change `MODEL_ARCH` to try different models ('deeponet', 'fno', 'unet')\n- **Cell 5**: Adjust hyperparameters (epochs, learning rate, etc.) in TrainingConfig\n- Run all cells sequentially to train and compare all 6 loss types automatically!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}